# -*- coding: utf-8 -*-
"""multimodal.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17fjwYIihA0j8d1OoiCr8lfJNu9S99TQS
"""

!git clone "https://github.com/convman/Multimodal-MOSEI.git"

cd Multimodal-MOSEI/

!wget "http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/labels/mosi2uni_Test_labels_surprise.csv"
!wget "http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/labels/mosi2uni_Train_labels_surprise.csv"

import pandas as pd
import numpy as np
import h5py

Test_labels_surprise = pd.read_csv("mosi2uni_Test_labels_surprise.csv",header=None)

Train_labels_surprise = pd.read_csv("mosi2uni_Train_labels_surprise.csv",header=None)

!wget "http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/data/audio_test.h5"
!wget "http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/data/audio_train.h5"
!wget "http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/data/text_test_emb.h5"
!wget "http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/data/text_train_emb.h5"
!wget "http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/data/video_test.h5"
!wget "http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/data/video_train.h5"

video_train = h5py.File("video_train.h5","r")
print(list(video_train.keys()))
video_train = np.array(video_train.get('d1'))
video_train.shape

video_test = h5py.File("video_test.h5","r")
print(list(video_test.keys()))
video_test = np.array(video_test.get('d1'))
video_test.shape

audio_train = h5py.File("audio_train.h5","r")
print(list(audio_train.keys()))
audio_train = np.array(audio_train.get('d1'))
audio_train.shape

audio_test = h5py.File("audio_test.h5","r")
print(list(audio_test.keys()))
audio_test = np.array(audio_test.get('d1'))
audio_test.shape

text_train_emb = h5py.File("text_train_emb.h5","r")
print(list(text_train_emb.keys()))
text_train_emb = np.array(text_train_emb.get('d1'))
text_train_emb.shape

text_test_emb = h5py.File("text_test_emb.h5","r")
print(list(text_test_emb.keys()))
text_test_emb = np.array(text_test_emb.get('d1'))
text_test_emb.shape

from keras.models import load_model
import keras
from google.colab import files	
from keras.models import load_model
from keras.models import Model,Sequential,Model
from keras.layers import LSTM,Dense,Input,concatenate
from keras import callbacks
from keras.callbacks import EarlyStopping, ModelCheckpoint

model_audio_surprise = load_model("unimodal baselines/weights/audio/weights_rnn_surprise.h5")
model_video_surprise = load_model("unimodal baselines/weights/video/weights_rnn_surprise.h5")
model_text_surprise = load_model("unimodal baselines/weights/text/weights_rnn_surprise.h5")

surprise_video = Sequential()
surprise_audio = Sequential()
surprise_text = Sequential()

for layer in model_video_surprise.layers[:-2]:   #(typical late fusion)
    surprise_video.add(layer)
for layer in surprise_video.layers:
    layer.trainable = False
surprise_video.add(Dense(32,activation='relu'))

for layer in model_audio_surprise.layers[:-2]:   #(typical late fusion)
    surprise_audio.add(layer)
for layer in surprise_audio.layers:
    layer.trainable = False
surprise_audio.add(Dense(32,activation='relu'))

for layer in model_text_surprise.layers[:-2]:   #(typical late fusion)
    surprise_text.add(layer)
for layer in surprise_text.layers:
    layer.trainable = False
surprise_text.add(Dense(32,activation='relu'))

surprise_audio.summary()

i1 = Input(shape=(20,35),name='i1')
i2 = Input(shape=(20,74),name='i2')
i3 = Input(shape=(20,300),name='i3')

o1 = surprise_video(i1)
o2 = surprise_audio(i2)
o3 = surprise_text(i3)
merge = concatenate([o1,o2,o3])
y = Dense(32,activation='relu')(merge)
y = Dense(32,activation='relu')(y)
y = Dense(1,activation='sigmoid')(y)

model = Model(inputs=[i1,i2,i3],outputs=y)
model.compile('adam','binary_crossentropy',metrics=['accuracy'])
model.summary()

es = EarlyStopping(monitor='val_loss',mode='min' ,patience=5, min_delta=0.0001,verbose=1)
mcp = ModelCheckpoint("multimodal_surprise.h5",monitor='val_loss',verbose=1)
model.fit({'i1':video_train,'i2':audio_train,'i3':text_train_emb},Train_labels_surprise,64,20,validation_split=0.1,callbacks=[es, mcp])
model.evaluate({'i1':video_test,'i2':audio_test,'i3':text_test_emb},Test_labels_surprise)

files.download('multimodal_surprise.h5')