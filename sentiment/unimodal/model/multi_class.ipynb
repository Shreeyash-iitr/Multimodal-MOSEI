{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multiclass.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoS2Vx-Q4GGA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "ee15dd7d-b6a0-4071-aa22-c157828f4800"
      },
      "source": [
        "!git clone \"https://github.com/convman/Multimodal-MOSEI\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Multimodal-MOSEI'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects:   4% (1/25)   \u001b[K\rremote: Counting objects:   8% (2/25)   \u001b[K\rremote: Counting objects:  12% (3/25)   \u001b[K\rremote: Counting objects:  16% (4/25)   \u001b[K\rremote: Counting objects:  20% (5/25)   \u001b[K\rremote: Counting objects:  24% (6/25)   \u001b[K\rremote: Counting objects:  28% (7/25)   \u001b[K\rremote: Counting objects:  32% (8/25)   \u001b[K\rremote: Counting objects:  36% (9/25)   \u001b[K\rremote: Counting objects:  40% (10/25)   \u001b[K\rremote: Counting objects:  44% (11/25)   \u001b[K\rremote: Counting objects:  48% (12/25)   \u001b[K\rremote: Counting objects:  52% (13/25)   \u001b[K\rremote: Counting objects:  56% (14/25)   \u001b[K\rremote: Counting objects:  60% (15/25)   \u001b[K\rremote: Counting objects:  64% (16/25)   \u001b[K\rremote: Counting objects:  68% (17/25)   \u001b[K\rremote: Counting objects:  72% (18/25)   \u001b[K\rremote: Counting objects:  76% (19/25)   \u001b[K\rremote: Counting objects:  80% (20/25)   \u001b[K\rremote: Counting objects:  84% (21/25)   \u001b[K\rremote: Counting objects:  88% (22/25)   \u001b[K\rremote: Counting objects:  92% (23/25)   \u001b[K\rremote: Counting objects:  96% (24/25)   \u001b[K\rremote: Counting objects: 100% (25/25)   \u001b[K\rremote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 173 (delta 8), reused 10 (delta 2), pack-reused 148\n",
            "Receiving objects: 100% (173/173), 459.20 MiB | 43.55 MiB/s, done.\n",
            "Resolving deltas: 100% (59/59), done.\n",
            "Checking out files: 100% (60/60), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KKYSVRE4aNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dd88fa4f-859e-45ff-d84c-340868d08ddb"
      },
      "source": [
        "cd Multimodal-MOSEI/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Multimodal-MOSEI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETI46XhZ4jAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod +x data/dataset_download.sh\n",
        "!./data/dataset_download.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpGRoMMq4sdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import pandas as pd\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import load_model\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from time import time\n",
        "from keras import layers\n",
        "from google.colab import files\t\n",
        "from keras.models import load_model\n",
        "from keras.models import Model,Sequential,Model\n",
        "from keras.layers import *\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras import callbacks\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.metrics import \n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCDEOAkc-Fr8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4411bad3-4988-49f4-873c-2e5e67d0f9ac"
      },
      "source": [
        "train_2class = pd.read_csv(\"mosi2uni_Train_labels_2class.csv\",header=None)\n",
        "train_5class = pd.read_csv(\"mosi2uni_Train_labels_5class.csv\",header=None)\n",
        "train_7class = pd.read_csv(\"mosi2uni_Train_labels_7class.csv\",header=None)\n",
        "\n",
        "test_2class = pd.read_csv(\"mosi2uni_Test_labels_2class.csv\",header=None)\n",
        "test_5class = pd.read_csv(\"mosi2uni_Test_labels_5class.csv\",header=None)\n",
        "test_7class = pd.read_csv(\"mosi2uni_Test_labels_7class.csv\",header=None)\n",
        "\n",
        "train_2class.loc[train_2class[0]>1] = 1\n",
        "train_5class.loc[train_5class[0]>4] = 4\n",
        "train_7class.loc[train_7class[0]>6] = 6\n",
        "\n",
        "test_2class.loc[test_2class[0]>1] = 1\n",
        "test_5class.loc[test_5class[0]>4] = 4\n",
        "test_7class.loc[test_7class[0]>6] = 6\n",
        "\n",
        "train_5class = to_categorical(train_5class, num_classes=5)\n",
        "train_7class = to_categorical(train_7class, num_classes=7)\n",
        "\n",
        "test_5class = to_categorical(test_5class, num_classes=5)\n",
        "test_7class = to_categorical(test_7class, num_classes=7)\n",
        "\n",
        "print(train_2class.shape, train_5class.shape, train_7class.shape)\n",
        "print(test_2class.shape, test_5class.shape, test_7class.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15290, 1) (15290, 5) (15290, 7)\n",
            "(4832, 1) (4832, 5) (4832, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxxNuoKU-xFu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9f5aa488-63c0-41d3-a99e-01ae247f66a7"
      },
      "source": [
        "video_train = h5py.File(\"video_train.h5\",\"r\")\n",
        "video_train = np.array(video_train.get('d1'))\n",
        "video_test = h5py.File(\"video_test.h5\",\"r\")\n",
        "video_test = np.array(video_test.get('d1'))\n",
        "print(video_train.shape, video_test.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15290, 20, 35) (4832, 20, 35)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXkmDCYfOGij",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a03b72ce-ec6b-4082-9796-a0a2d4ca273d"
      },
      "source": [
        "audio_train = h5py.File(\"audio_train.h5\",\"r\")\n",
        "audio_train = np.array(audio_train.get('d1'))\n",
        "audio_test = h5py.File(\"audio_test.h5\",\"r\")\n",
        "audio_test = np.array(audio_test.get('d1'))\n",
        "print(audio_train.shape, audio_test.shape)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15290, 20, 74) (4832, 20, 74)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlJ9kqAPOGUi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "89aa7823-f4da-48e3-c574-7da2e560833f"
      },
      "source": [
        "text_train = h5py.File(\"text_train_emb.h5\",\"r\")\n",
        "text_train = np.array(text_train.get('d1'))\n",
        "text_test = h5py.File(\"text_test_emb.h5\",\"r\")\n",
        "text_test = np.array(text_test.get('d1'))\n",
        "print(text_train.shape, text_test.shape)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15290, 20, 300) (4832, 20, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LvIhHZaAVQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = Input(shape=(20,35))\n",
        "x = LSTM(units=256,return_sequences=True)(i)\n",
        "x = LSTM(units=256,return_sequences=True)(x)\n",
        "x = LSTM(units=128,return_sequences=True)(x)\n",
        "x = LSTM(units=128,return_sequences=True)(x)\n",
        "x = LSTM(units=64,return_sequences=True)(x)\n",
        "x = LSTM(units=64,return_sequences=True)(x)\n",
        "x = LSTM(units=32,return_sequences=True)(x)\n",
        "x = LSTM(units=32,return_sequences=False)(x)\n",
        "x = Dense(units=32,activation='relu')(x)\n",
        "x = Dropout(rate=0.15)(x)\n",
        "x = Dense(units=32,activation='relu')(x)\n",
        "o_2class = Dense(1,activation='sigmoid')(x)\n",
        "o_5class = Dense(5,activation='softmax')(x)\n",
        "o_7class = Dense(7,activation='softmax')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VmqjYFxDlDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "video_2class = Model(inputs = i, outputs = o_2class)\n",
        "video_5class = Model(inputs = i, outputs = o_5class)\n",
        "video_7class = Model(inputs = i, outputs = o_7class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAhF_94oRosa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i2 = Input(shape=(20,74))\n",
        "x = LSTM(units=256,return_sequences=True)(i2)\n",
        "x = LSTM(units=256,return_sequences=True)(x)\n",
        "x = LSTM(units=128,return_sequences=True)(x)\n",
        "x = LSTM(units=128,return_sequences=True)(x)\n",
        "x = LSTM(units=64,return_sequences=True)(x)\n",
        "x = LSTM(units=64,return_sequences=True)(x)\n",
        "x = LSTM(units=32,return_sequences=True)(x)\n",
        "x = LSTM(units=32,return_sequences=False)(x)\n",
        "x = Dense(units=32,activation='relu')(x)\n",
        "x = Dropout(rate=0.15)(x)\n",
        "x = Dense(units=32,activation='relu')(x)\n",
        "o_2class = Dense(1,activation='sigmoid')(x)\n",
        "o_5class = Dense(5,activation='softmax')(x)\n",
        "o_7class = Dense(7,activation='softmax')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idRprecZRNAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "audio_2class = Model(inputs = i2, outputs = o_2class)\n",
        "audio_5class = Model(inputs = i2, outputs = o_5class)\n",
        "audio_7class = Model(inputs = i2, outputs = o_7class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTFtjQ2iSgh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i3 = Input(shape=(20,300))\n",
        "x = LSTM(units=256,return_sequences=True)(i3)\n",
        "x = LSTM(units=256,return_sequences=True)(x)\n",
        "x = LSTM(units=128,return_sequences=True)(x)\n",
        "x = LSTM(units=128,return_sequences=True)(x)\n",
        "x = LSTM(units=64,return_sequences=True)(x)\n",
        "x = LSTM(units=64,return_sequences=True)(x)\n",
        "x = LSTM(units=32,return_sequences=True)(x)\n",
        "x = LSTM(units=32,return_sequences=False)(x)\n",
        "x = Dense(units=32,activation='relu')(x)\n",
        "x = Dropout(rate=0.15)(x)\n",
        "x = Dense(units=32,activation='relu')(x)\n",
        "o_2class = Dense(1,activation='sigmoid')(x)\n",
        "o_5class = Dense(5,activation='softmax')(x)\n",
        "o_7class = Dense(7,activation='softmax')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQRjD2fPSoPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_2class = Model(inputs = i3, outputs = o_2class)\n",
        "text_5class = Model(inputs = i3, outputs = o_5class)\n",
        "text_7class = Model(inputs = i3, outputs = o_7class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iicUYPQOEBc9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "62904e14-1c71-4d8a-a225-ca731043aced"
      },
      "source": [
        "video_5class.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 20, 35)            0         \n",
            "_________________________________________________________________\n",
            "lstm_17 (LSTM)               (None, 20, 256)           299008    \n",
            "_________________________________________________________________\n",
            "lstm_18 (LSTM)               (None, 20, 256)           525312    \n",
            "_________________________________________________________________\n",
            "lstm_19 (LSTM)               (None, 20, 128)           197120    \n",
            "_________________________________________________________________\n",
            "lstm_20 (LSTM)               (None, 20, 128)           131584    \n",
            "_________________________________________________________________\n",
            "lstm_21 (LSTM)               (None, 20, 64)            49408     \n",
            "_________________________________________________________________\n",
            "lstm_22 (LSTM)               (None, 20, 64)            33024     \n",
            "_________________________________________________________________\n",
            "lstm_23 (LSTM)               (None, 20, 32)            12416     \n",
            "_________________________________________________________________\n",
            "lstm_24 (LSTM)               (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 5)                 165       \n",
            "=================================================================\n",
            "Total params: 1,258,469\n",
            "Trainable params: 1,258,469\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXSuFrcMEEvA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4a3c3499-8d6a-40d3-99e9-49e41339d3da"
      },
      "source": [
        "video_2class.compile('adam','binary_crossentropy',['accuracy','mae'])\n",
        "es = EarlyStopping(monitor='val_loss',mode='min' ,patience=5, min_delta=0.0001,verbose=1)\n",
        "mcp = ModelCheckpoint(\"video_2class.h5\",monitor='val_loss',verbose=1)\n",
        "video_2class.fit(video_train,train_2class,batch_size=128,epochs=20,validation_split=0.1,callbacks=[es, mcp])\n",
        "print(\"Evaluating the model=====================================================\")\n",
        "print(video_2class.evaluate(video_test,test_2class))\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 13761 samples, validate on 1529 samples\n",
            "Epoch 1/20\n",
            "13761/13761 [==============================] - 33s 2ms/step - loss: 0.6320 - acc: 0.6382 - mean_absolute_error: 0.4425 - val_loss: 0.6359 - val_acc: 0.6364 - val_mean_absolute_error: 0.4336\n",
            "\n",
            "Epoch 00001: saving model to video_2class.h5\n",
            "Epoch 2/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.6149 - acc: 0.6404 - mean_absolute_error: 0.4272 - val_loss: 0.6298 - val_acc: 0.6069 - val_mean_absolute_error: 0.4338\n",
            "\n",
            "Epoch 00002: saving model to video_2class.h5\n",
            "Epoch 3/20\n",
            "13761/13761 [==============================] - 25s 2ms/step - loss: 0.6151 - acc: 0.6397 - mean_absolute_error: 0.4263 - val_loss: 0.6259 - val_acc: 0.6377 - val_mean_absolute_error: 0.4361\n",
            "\n",
            "Epoch 00003: saving model to video_2class.h5\n",
            "Epoch 4/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.6137 - acc: 0.6432 - mean_absolute_error: 0.4252 - val_loss: 0.6277 - val_acc: 0.6337 - val_mean_absolute_error: 0.4474\n",
            "\n",
            "Epoch 00004: saving model to video_2class.h5\n",
            "Epoch 5/20\n",
            "13761/13761 [==============================] - 25s 2ms/step - loss: 0.6125 - acc: 0.6579 - mean_absolute_error: 0.4250 - val_loss: 0.6305 - val_acc: 0.6246 - val_mean_absolute_error: 0.4245\n",
            "\n",
            "Epoch 00005: saving model to video_2class.h5\n",
            "Epoch 6/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.6091 - acc: 0.6620 - mean_absolute_error: 0.4207 - val_loss: 0.6285 - val_acc: 0.6364 - val_mean_absolute_error: 0.4278\n",
            "\n",
            "Epoch 00006: saving model to video_2class.h5\n",
            "Epoch 7/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.6108 - acc: 0.6476 - mean_absolute_error: 0.4223 - val_loss: 0.6237 - val_acc: 0.6351 - val_mean_absolute_error: 0.4339\n",
            "\n",
            "Epoch 00007: saving model to video_2class.h5\n",
            "Epoch 8/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.6069 - acc: 0.6590 - mean_absolute_error: 0.4196 - val_loss: 0.6256 - val_acc: 0.6305 - val_mean_absolute_error: 0.4343\n",
            "\n",
            "Epoch 00008: saving model to video_2class.h5\n",
            "Epoch 9/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.6043 - acc: 0.6702 - mean_absolute_error: 0.4167 - val_loss: 0.6170 - val_acc: 0.6560 - val_mean_absolute_error: 0.4318\n",
            "\n",
            "Epoch 00009: saving model to video_2class.h5\n",
            "Epoch 10/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.6024 - acc: 0.6723 - mean_absolute_error: 0.4154 - val_loss: 0.6189 - val_acc: 0.6436 - val_mean_absolute_error: 0.4254\n",
            "\n",
            "Epoch 00010: saving model to video_2class.h5\n",
            "Epoch 11/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.6010 - acc: 0.6726 - mean_absolute_error: 0.4133 - val_loss: 0.6220 - val_acc: 0.6547 - val_mean_absolute_error: 0.4260\n",
            "\n",
            "Epoch 00011: saving model to video_2class.h5\n",
            "Epoch 12/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.6002 - acc: 0.6789 - mean_absolute_error: 0.4128 - val_loss: 0.6213 - val_acc: 0.6527 - val_mean_absolute_error: 0.4272\n",
            "\n",
            "Epoch 00012: saving model to video_2class.h5\n",
            "Epoch 13/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.5959 - acc: 0.6838 - mean_absolute_error: 0.4095 - val_loss: 0.6194 - val_acc: 0.6593 - val_mean_absolute_error: 0.4212\n",
            "\n",
            "Epoch 00013: saving model to video_2class.h5\n",
            "Epoch 14/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.5956 - acc: 0.6811 - mean_absolute_error: 0.4080 - val_loss: 0.6326 - val_acc: 0.6239 - val_mean_absolute_error: 0.4344\n",
            "\n",
            "Epoch 00014: saving model to video_2class.h5\n",
            "Epoch 00014: early stopping\n",
            "Evaluating the model=====================================================\n",
            "4832/4832 [==============================] - 13s 3ms/step\n",
            "[0.5945584114813647, 0.6783940397350994, 0.4128443490195748]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Dsxs4z-Fex9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "outputId": "21d683dd-677d-402c-df88-bd29d1741bd7"
      },
      "source": [
        "video_5class.compile('adam','categorical_crossentropy',['accuracy','mae'])\n",
        "es = EarlyStopping(monitor='val_loss',mode='min' ,patience=5, min_delta=0.0001,verbose=1)\n",
        "mcp = ModelCheckpoint(\"video_5class.h5\",monitor='val_loss',verbose=1)\n",
        "video_5class.fit(video_train,train_5class,batch_size=128,epochs=20,validation_split=0.1,callbacks=[es, mcp])\n",
        "print(\"Evaluating the model=====================================================\")\n",
        "print(video_5class.evaluate(video_test,test_5class))\n",
        "  "
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 13761 samples, validate on 1529 samples\n",
            "Epoch 1/20\n",
            "13761/13761 [==============================] - 34s 2ms/step - loss: 1.4479 - acc: 0.3967 - mean_absolute_error: 0.2931 - val_loss: 1.3231 - val_acc: 0.4532 - val_mean_absolute_error: 0.2800\n",
            "\n",
            "Epoch 00001: saving model to video_5class.h5\n",
            "Epoch 2/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.3433 - acc: 0.4280 - mean_absolute_error: 0.2784 - val_loss: 1.3035 - val_acc: 0.4526 - val_mean_absolute_error: 0.2761\n",
            "\n",
            "Epoch 00002: saving model to video_5class.h5\n",
            "Epoch 3/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.3268 - acc: 0.4358 - mean_absolute_error: 0.2759 - val_loss: 1.2930 - val_acc: 0.4637 - val_mean_absolute_error: 0.2712\n",
            "\n",
            "Epoch 00003: saving model to video_5class.h5\n",
            "Epoch 4/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.3220 - acc: 0.4373 - mean_absolute_error: 0.2748 - val_loss: 1.3069 - val_acc: 0.4447 - val_mean_absolute_error: 0.2721\n",
            "\n",
            "Epoch 00004: saving model to video_5class.h5\n",
            "Epoch 5/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.3209 - acc: 0.4375 - mean_absolute_error: 0.2745 - val_loss: 1.3032 - val_acc: 0.4519 - val_mean_absolute_error: 0.2748\n",
            "\n",
            "Epoch 00005: saving model to video_5class.h5\n",
            "Epoch 6/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.3200 - acc: 0.4372 - mean_absolute_error: 0.2745 - val_loss: 1.3006 - val_acc: 0.4506 - val_mean_absolute_error: 0.2747\n",
            "\n",
            "Epoch 00006: saving model to video_5class.h5\n",
            "Epoch 7/20\n",
            "13761/13761 [==============================] - 25s 2ms/step - loss: 1.3115 - acc: 0.4397 - mean_absolute_error: 0.2733 - val_loss: 1.2996 - val_acc: 0.4552 - val_mean_absolute_error: 0.2719\n",
            "\n",
            "Epoch 00007: saving model to video_5class.h5\n",
            "Epoch 8/20\n",
            "13761/13761 [==============================] - 25s 2ms/step - loss: 1.3083 - acc: 0.4426 - mean_absolute_error: 0.2723 - val_loss: 1.2994 - val_acc: 0.4709 - val_mean_absolute_error: 0.2707\n",
            "\n",
            "Epoch 00008: saving model to video_5class.h5\n",
            "Epoch 00008: early stopping\n",
            "Evaluating the model=====================================================\n",
            "4832/4832 [==============================] - 13s 3ms/step\n",
            "[1.3351095074059947, 0.42135761589403975, 0.2756845127075713]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YA8QGqAL5SK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "outputId": "f86bd6a2-793d-49b4-aa9f-cefc452a7ff0"
      },
      "source": [
        "video_7class.compile('adam','categorical_crossentropy',['accuracy','mae'])\n",
        "es = EarlyStopping(monitor='val_loss',mode='min' ,patience=5, min_delta=0.0001,verbose=1)\n",
        "mcp = ModelCheckpoint(\"video_7class.h5\",monitor='val_loss',verbose=1)\n",
        "video_7class.fit(video_train,train_7class,batch_size=128,epochs=20,validation_split=0.1,callbacks=[es, mcp])\n",
        "print(\"Evaluating the model=====================================================\")\n",
        "print(video_7class.evaluate(video_test,test_7class))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 13761 samples, validate on 1529 samples\n",
            "Epoch 1/20\n",
            "13761/13761 [==============================] - 34s 2ms/step - loss: 1.5197 - acc: 0.4053 - mean_absolute_error: 0.2085 - val_loss: 1.3666 - val_acc: 0.4532 - val_mean_absolute_error: 0.2002\n",
            "\n",
            "Epoch 00001: saving model to video_7class.h5\n",
            "Epoch 2/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.4507 - acc: 0.4109 - mean_absolute_error: 0.2036 - val_loss: 1.3615 - val_acc: 0.4532 - val_mean_absolute_error: 0.2001\n",
            "\n",
            "Epoch 00002: saving model to video_7class.h5\n",
            "Epoch 3/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.4422 - acc: 0.4144 - mean_absolute_error: 0.2032 - val_loss: 1.3627 - val_acc: 0.4532 - val_mean_absolute_error: 0.2004\n",
            "\n",
            "Epoch 00003: saving model to video_7class.h5\n",
            "Epoch 4/20\n",
            "13761/13761 [==============================] - 25s 2ms/step - loss: 1.4363 - acc: 0.4189 - mean_absolute_error: 0.2028 - val_loss: 1.3514 - val_acc: 0.4565 - val_mean_absolute_error: 0.1970\n",
            "\n",
            "Epoch 00004: saving model to video_7class.h5\n",
            "Epoch 5/20\n",
            "13761/13761 [==============================] - 25s 2ms/step - loss: 1.4246 - acc: 0.4234 - mean_absolute_error: 0.2013 - val_loss: 1.3600 - val_acc: 0.4402 - val_mean_absolute_error: 0.1978\n",
            "\n",
            "Epoch 00005: saving model to video_7class.h5\n",
            "Epoch 6/20\n",
            "13761/13761 [==============================] - 25s 2ms/step - loss: 1.4175 - acc: 0.4314 - mean_absolute_error: 0.2002 - val_loss: 1.3484 - val_acc: 0.4539 - val_mean_absolute_error: 0.1975\n",
            "\n",
            "Epoch 00006: saving model to video_7class.h5\n",
            "Epoch 7/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.4131 - acc: 0.4309 - mean_absolute_error: 0.2001 - val_loss: 1.3525 - val_acc: 0.4480 - val_mean_absolute_error: 0.1965\n",
            "\n",
            "Epoch 00007: saving model to video_7class.h5\n",
            "Epoch 8/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.4062 - acc: 0.4383 - mean_absolute_error: 0.1993 - val_loss: 1.3528 - val_acc: 0.4415 - val_mean_absolute_error: 0.1945\n",
            "\n",
            "Epoch 00008: saving model to video_7class.h5\n",
            "Epoch 9/20\n",
            "13761/13761 [==============================] - 25s 2ms/step - loss: 1.4020 - acc: 0.4398 - mean_absolute_error: 0.1981 - val_loss: 1.3523 - val_acc: 0.4506 - val_mean_absolute_error: 0.1976\n",
            "\n",
            "Epoch 00009: saving model to video_7class.h5\n",
            "Epoch 10/20\n",
            "13761/13761 [==============================] - 25s 2ms/step - loss: 1.3994 - acc: 0.4383 - mean_absolute_error: 0.1982 - val_loss: 1.3715 - val_acc: 0.4362 - val_mean_absolute_error: 0.2019\n",
            "\n",
            "Epoch 00010: saving model to video_7class.h5\n",
            "Epoch 11/20\n",
            "13761/13761 [==============================] - 25s 2ms/step - loss: 1.4013 - acc: 0.4420 - mean_absolute_error: 0.1987 - val_loss: 1.3613 - val_acc: 0.4369 - val_mean_absolute_error: 0.1991\n",
            "\n",
            "Epoch 00011: saving model to video_7class.h5\n",
            "Epoch 00011: early stopping\n",
            "Evaluating the model=====================================================\n",
            "4832/4832 [==============================] - 13s 3ms/step\n",
            "[1.4135554784181101, 0.42611754966887416, 0.2024023501288812]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT2RAiALMCgA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "outputId": "ac4e2134-ec8b-4f6a-b6e1-ec979b092508"
      },
      "source": [
        "audio_2class.compile('adam','binary_crossentropy',['accuracy','mae'])\n",
        "es = EarlyStopping(monitor='val_loss',mode='min' ,patience=5, min_delta=0.0001,verbose=1)\n",
        "mcp = ModelCheckpoint(\"audio_2class.h5\",monitor='val_loss',verbose=1)\n",
        "audio_2class.fit(audio_train,train_2class,batch_size=128,epochs=20,validation_split=0.1,callbacks=[es, mcp])\n",
        "print(\"Evaluating the model=====================================================\")\n",
        "print(audio_2class.evaluate(audio_test,test_2class))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 13761 samples, validate on 1529 samples\n",
            "Epoch 1/20\n",
            "13761/13761 [==============================] - 36s 3ms/step - loss: 0.6321 - acc: 0.6412 - mean_absolute_error: 0.4426 - val_loss: 0.6254 - val_acc: 0.6364 - val_mean_absolute_error: 0.4390\n",
            "\n",
            "Epoch 00001: saving model to audio_2class.h5\n",
            "Epoch 2/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.6186 - acc: 0.6412 - mean_absolute_error: 0.4309 - val_loss: 0.6261 - val_acc: 0.6364 - val_mean_absolute_error: 0.4377\n",
            "\n",
            "Epoch 00002: saving model to audio_2class.h5\n",
            "Epoch 3/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.6178 - acc: 0.6400 - mean_absolute_error: 0.4292 - val_loss: 0.6261 - val_acc: 0.6364 - val_mean_absolute_error: 0.4415\n",
            "\n",
            "Epoch 00003: saving model to audio_2class.h5\n",
            "Epoch 4/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.6165 - acc: 0.6412 - mean_absolute_error: 0.4290 - val_loss: 0.6254 - val_acc: 0.6364 - val_mean_absolute_error: 0.4355\n",
            "\n",
            "Epoch 00004: saving model to audio_2class.h5\n",
            "Epoch 5/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.6154 - acc: 0.6412 - mean_absolute_error: 0.4281 - val_loss: 0.6263 - val_acc: 0.6364 - val_mean_absolute_error: 0.4355\n",
            "\n",
            "Epoch 00005: saving model to audio_2class.h5\n",
            "Epoch 6/20\n",
            "13761/13761 [==============================] - 25s 2ms/step - loss: 0.6152 - acc: 0.6412 - mean_absolute_error: 0.4275 - val_loss: 0.6256 - val_acc: 0.6364 - val_mean_absolute_error: 0.4375\n",
            "\n",
            "Epoch 00006: saving model to audio_2class.h5\n",
            "Epoch 00006: early stopping\n",
            "Evaluating the model=====================================================\n",
            "4832/4832 [==============================] - 13s 3ms/step\n",
            "[0.5979205728169309, 0.6463162251655629, 0.4182871568281919]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPLNOw7VR4m7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "outputId": "3878afb7-9c58-4eb2-d36d-1ae9ef6ec7ef"
      },
      "source": [
        "audio_5class.compile('adam','categorical_crossentropy',['accuracy','mae'])\n",
        "es = EarlyStopping(monitor='val_loss',mode='min' ,patience=5, min_delta=0.0001,verbose=1)\n",
        "mcp = ModelCheckpoint(\"audio_5class.h5\",monitor='val_loss',verbose=1)\n",
        "audio_5class.fit(audio_train,train_5class,batch_size=128,epochs=20,validation_split=0.1,callbacks=[es, mcp])\n",
        "print(\"Evaluating the model=====================================================\")\n",
        "print(audio_5class.evaluate(audio_test,test_5class))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 13761 samples, validate on 1529 samples\n",
            "Epoch 1/20\n",
            "13761/13761 [==============================] - 37s 3ms/step - loss: 1.3891 - acc: 0.3966 - mean_absolute_error: 0.2862 - val_loss: 1.3032 - val_acc: 0.4532 - val_mean_absolute_error: 0.2759\n",
            "\n",
            "Epoch 00001: saving model to audio_5class.h5\n",
            "Epoch 2/20\n",
            "13761/13761 [==============================] - 25s 2ms/step - loss: 1.3508 - acc: 0.4090 - mean_absolute_error: 0.2801 - val_loss: 1.3029 - val_acc: 0.4532 - val_mean_absolute_error: 0.2751\n",
            "\n",
            "Epoch 00002: saving model to audio_5class.h5\n",
            "Epoch 3/20\n",
            "13761/13761 [==============================] - 25s 2ms/step - loss: 1.3457 - acc: 0.4118 - mean_absolute_error: 0.2795 - val_loss: 1.3033 - val_acc: 0.4532 - val_mean_absolute_error: 0.2757\n",
            "\n",
            "Epoch 00003: saving model to audio_5class.h5\n",
            "Epoch 4/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.3476 - acc: 0.4136 - mean_absolute_error: 0.2796 - val_loss: 1.3011 - val_acc: 0.4532 - val_mean_absolute_error: 0.2758\n",
            "\n",
            "Epoch 00004: saving model to audio_5class.h5\n",
            "Epoch 5/20\n",
            "13761/13761 [==============================] - 25s 2ms/step - loss: 1.3461 - acc: 0.4141 - mean_absolute_error: 0.2797 - val_loss: 1.2998 - val_acc: 0.4532 - val_mean_absolute_error: 0.2750\n",
            "\n",
            "Epoch 00005: saving model to audio_5class.h5\n",
            "Epoch 6/20\n",
            "13761/13761 [==============================] - 25s 2ms/step - loss: 1.3458 - acc: 0.4132 - mean_absolute_error: 0.2796 - val_loss: 1.3045 - val_acc: 0.4532 - val_mean_absolute_error: 0.2770\n",
            "\n",
            "Epoch 00006: saving model to audio_5class.h5\n",
            "Epoch 7/20\n",
            "13761/13761 [==============================] - 25s 2ms/step - loss: 1.3456 - acc: 0.4149 - mean_absolute_error: 0.2795 - val_loss: 1.3090 - val_acc: 0.4532 - val_mean_absolute_error: 0.2796\n",
            "\n",
            "Epoch 00007: saving model to audio_5class.h5\n",
            "Epoch 8/20\n",
            "13761/13761 [==============================] - 25s 2ms/step - loss: 1.3454 - acc: 0.4150 - mean_absolute_error: 0.2798 - val_loss: 1.3007 - val_acc: 0.4532 - val_mean_absolute_error: 0.2760\n",
            "\n",
            "Epoch 00008: saving model to audio_5class.h5\n",
            "Epoch 9/20\n",
            "13761/13761 [==============================] - 25s 2ms/step - loss: 1.3583 - acc: 0.4149 - mean_absolute_error: 0.2808 - val_loss: 1.3009 - val_acc: 0.4532 - val_mean_absolute_error: 0.2764\n",
            "\n",
            "Epoch 00009: saving model to audio_5class.h5\n",
            "Epoch 10/20\n",
            "13761/13761 [==============================] - 25s 2ms/step - loss: 1.3439 - acc: 0.4157 - mean_absolute_error: 0.2791 - val_loss: 1.3042 - val_acc: 0.4532 - val_mean_absolute_error: 0.2768\n",
            "\n",
            "Epoch 00010: saving model to audio_5class.h5\n",
            "Epoch 00010: early stopping\n",
            "Evaluating the model=====================================================\n",
            "4832/4832 [==============================] - 13s 3ms/step\n",
            "[1.3464281251098935, 0.4145281456953642, 0.2816332372411197]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmWbsBSvR-5L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8c8e0ec4-163c-46a4-9cad-6c42ce7386fd"
      },
      "source": [
        "audio_7class.compile('adam','categorical_crossentropy',['accuracy','mae'])\n",
        "es = EarlyStopping(monitor='val_loss',mode='min' ,patience=5, min_delta=0.0001,verbose=1)\n",
        "mcp = ModelCheckpoint(\"audio_7class.h5\",monitor='val_loss',verbose=1)\n",
        "audio_7class.fit(audio_train,train_7class,batch_size=128,epochs=20,validation_split=0.1,callbacks=[es, mcp])\n",
        "print(\"Evaluating the model=====================================================\")\n",
        "print(audio_7class.evaluate(audio_test,test_7class))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 13761 samples, validate on 1529 samples\n",
            "Epoch 1/20\n",
            "13761/13761 [==============================] - 37s 3ms/step - loss: 1.5104 - acc: 0.3886 - mean_absolute_error: 0.2092 - val_loss: 1.3599 - val_acc: 0.4532 - val_mean_absolute_error: 0.2002\n",
            "\n",
            "Epoch 00001: saving model to audio_7class.h5\n",
            "Epoch 2/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.4428 - acc: 0.4072 - mean_absolute_error: 0.2034 - val_loss: 1.3534 - val_acc: 0.4532 - val_mean_absolute_error: 0.1993\n",
            "\n",
            "Epoch 00002: saving model to audio_7class.h5\n",
            "Epoch 3/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.4408 - acc: 0.4126 - mean_absolute_error: 0.2031 - val_loss: 1.3552 - val_acc: 0.4532 - val_mean_absolute_error: 0.2002\n",
            "\n",
            "Epoch 00003: saving model to audio_7class.h5\n",
            "Epoch 4/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.4367 - acc: 0.4142 - mean_absolute_error: 0.2028 - val_loss: 1.3567 - val_acc: 0.4532 - val_mean_absolute_error: 0.2007\n",
            "\n",
            "Epoch 00004: saving model to audio_7class.h5\n",
            "Epoch 5/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.4346 - acc: 0.4118 - mean_absolute_error: 0.2029 - val_loss: 1.3531 - val_acc: 0.4532 - val_mean_absolute_error: 0.1984\n",
            "\n",
            "Epoch 00005: saving model to audio_7class.h5\n",
            "Epoch 6/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.4344 - acc: 0.4146 - mean_absolute_error: 0.2027 - val_loss: 1.3515 - val_acc: 0.4532 - val_mean_absolute_error: 0.1983\n",
            "\n",
            "Epoch 00006: saving model to audio_7class.h5\n",
            "Epoch 7/20\n",
            "13761/13761 [==============================] - 25s 2ms/step - loss: 1.4344 - acc: 0.4137 - mean_absolute_error: 0.2028 - val_loss: 1.3491 - val_acc: 0.4532 - val_mean_absolute_error: 0.1963\n",
            "\n",
            "Epoch 00007: saving model to audio_7class.h5\n",
            "Epoch 8/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.4334 - acc: 0.4145 - mean_absolute_error: 0.2027 - val_loss: 1.3476 - val_acc: 0.4532 - val_mean_absolute_error: 0.1963\n",
            "\n",
            "Epoch 00008: saving model to audio_7class.h5\n",
            "Epoch 9/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.4338 - acc: 0.4153 - mean_absolute_error: 0.2026 - val_loss: 1.3539 - val_acc: 0.4532 - val_mean_absolute_error: 0.1994\n",
            "\n",
            "Epoch 00009: saving model to audio_7class.h5\n",
            "Epoch 10/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.4335 - acc: 0.4123 - mean_absolute_error: 0.2027 - val_loss: 1.3466 - val_acc: 0.4532 - val_mean_absolute_error: 0.1969\n",
            "\n",
            "Epoch 00010: saving model to audio_7class.h5\n",
            "Epoch 11/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.4334 - acc: 0.4136 - mean_absolute_error: 0.2026 - val_loss: 1.3539 - val_acc: 0.4532 - val_mean_absolute_error: 0.1996\n",
            "\n",
            "Epoch 00011: saving model to audio_7class.h5\n",
            "Epoch 12/20\n",
            "13761/13761 [==============================] - 25s 2ms/step - loss: 1.4323 - acc: 0.4150 - mean_absolute_error: 0.2025 - val_loss: 1.3535 - val_acc: 0.4532 - val_mean_absolute_error: 0.2000\n",
            "\n",
            "Epoch 00012: saving model to audio_7class.h5\n",
            "Epoch 13/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.4322 - acc: 0.4149 - mean_absolute_error: 0.2027 - val_loss: 1.3563 - val_acc: 0.4532 - val_mean_absolute_error: 0.2001\n",
            "\n",
            "Epoch 00013: saving model to audio_7class.h5\n",
            "Epoch 14/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.4329 - acc: 0.4144 - mean_absolute_error: 0.2027 - val_loss: 1.3514 - val_acc: 0.4532 - val_mean_absolute_error: 0.1985\n",
            "\n",
            "Epoch 00014: saving model to audio_7class.h5\n",
            "Epoch 15/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.4328 - acc: 0.4134 - mean_absolute_error: 0.2027 - val_loss: 1.3545 - val_acc: 0.4532 - val_mean_absolute_error: 0.1996\n",
            "\n",
            "Epoch 00015: saving model to audio_7class.h5\n",
            "Epoch 00015: early stopping\n",
            "Evaluating the model=====================================================\n",
            "4832/4832 [==============================] - 13s 3ms/step\n",
            "[1.4257170802710073, 0.4145281456953642, 0.20394446488642534]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka5xk-eQSFgW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "062aaeea-dcf5-41dd-8ebc-04e99aebdcee"
      },
      "source": [
        "text_2class.compile('adam','binary_crossentropy',['accuracy','mae'])\n",
        "es = EarlyStopping(monitor='val_loss',mode='min' ,patience=5, min_delta=0.0001,verbose=1)\n",
        "mcp = ModelCheckpoint(\"text_2class.h5\",monitor='val_loss',verbose=1)\n",
        "text_2class.fit(text_train,train_2class,batch_size=128,epochs=20,validation_split=0.1,callbacks=[es, mcp])\n",
        "print(\"Evaluating the model=====================================================\")\n",
        "print(text_2class.evaluate(text_test,test_2class))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 13761 samples, validate on 1529 samples\n",
            "Epoch 1/20\n",
            "13761/13761 [==============================] - 39s 3ms/step - loss: 0.6574 - acc: 0.6407 - mean_absolute_error: 0.4633 - val_loss: 0.6558 - val_acc: 0.6364 - val_mean_absolute_error: 0.4659\n",
            "\n",
            "Epoch 00001: saving model to text_2class.h5\n",
            "Epoch 2/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.6535 - acc: 0.6412 - mean_absolute_error: 0.4616 - val_loss: 0.6557 - val_acc: 0.6364 - val_mean_absolute_error: 0.4604\n",
            "\n",
            "Epoch 00002: saving model to text_2class.h5\n",
            "Epoch 3/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.6532 - acc: 0.6403 - mean_absolute_error: 0.4605 - val_loss: 0.6574 - val_acc: 0.5755 - val_mean_absolute_error: 0.4690\n",
            "\n",
            "Epoch 00003: saving model to text_2class.h5\n",
            "Epoch 4/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.6464 - acc: 0.6396 - mean_absolute_error: 0.4521 - val_loss: 0.6585 - val_acc: 0.6364 - val_mean_absolute_error: 0.4730\n",
            "\n",
            "Epoch 00004: saving model to text_2class.h5\n",
            "Epoch 5/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.6541 - acc: 0.6412 - mean_absolute_error: 0.4619 - val_loss: 0.6554 - val_acc: 0.6364 - val_mean_absolute_error: 0.4653\n",
            "\n",
            "Epoch 00005: saving model to text_2class.h5\n",
            "Epoch 6/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.6531 - acc: 0.6412 - mean_absolute_error: 0.4594 - val_loss: 0.6561 - val_acc: 0.6364 - val_mean_absolute_error: 0.4682\n",
            "\n",
            "Epoch 00006: saving model to text_2class.h5\n",
            "Epoch 7/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.6528 - acc: 0.6412 - mean_absolute_error: 0.4607 - val_loss: 0.6545 - val_acc: 0.6364 - val_mean_absolute_error: 0.4588\n",
            "\n",
            "Epoch 00007: saving model to text_2class.h5\n",
            "Epoch 8/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.6525 - acc: 0.6412 - mean_absolute_error: 0.4600 - val_loss: 0.6550 - val_acc: 0.6364 - val_mean_absolute_error: 0.4601\n",
            "\n",
            "Epoch 00008: saving model to text_2class.h5\n",
            "Epoch 9/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.6519 - acc: 0.6417 - mean_absolute_error: 0.4584 - val_loss: 0.6513 - val_acc: 0.6429 - val_mean_absolute_error: 0.4636\n",
            "\n",
            "Epoch 00009: saving model to text_2class.h5\n",
            "Epoch 10/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.6502 - acc: 0.6444 - mean_absolute_error: 0.4588 - val_loss: 0.6546 - val_acc: 0.6351 - val_mean_absolute_error: 0.4614\n",
            "\n",
            "Epoch 00010: saving model to text_2class.h5\n",
            "Epoch 11/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.6504 - acc: 0.6452 - mean_absolute_error: 0.4578 - val_loss: 0.6582 - val_acc: 0.6318 - val_mean_absolute_error: 0.4584\n",
            "\n",
            "Epoch 00011: saving model to text_2class.h5\n",
            "Epoch 12/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.6508 - acc: 0.6449 - mean_absolute_error: 0.4575 - val_loss: 0.6560 - val_acc: 0.6357 - val_mean_absolute_error: 0.4652\n",
            "\n",
            "Epoch 00012: saving model to text_2class.h5\n",
            "Epoch 13/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.6510 - acc: 0.6440 - mean_absolute_error: 0.4586 - val_loss: 0.6542 - val_acc: 0.6377 - val_mean_absolute_error: 0.4588\n",
            "\n",
            "Epoch 00013: saving model to text_2class.h5\n",
            "Epoch 14/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 0.6508 - acc: 0.6454 - mean_absolute_error: 0.4582 - val_loss: 0.6547 - val_acc: 0.6364 - val_mean_absolute_error: 0.4602\n",
            "\n",
            "Epoch 00014: saving model to text_2class.h5\n",
            "Epoch 00014: early stopping\n",
            "Evaluating the model=====================================================\n",
            "4832/4832 [==============================] - 13s 3ms/step\n",
            "[0.6480241856038176, 0.6479718543046358, 0.4568701384478057]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgvCCd3LS8jT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "outputId": "4c5f1709-30bf-4431-ba9b-2c9325a609aa"
      },
      "source": [
        "text_5class.compile('adam','categorical_crossentropy',['accuracy','mae'])\n",
        "es = EarlyStopping(monitor='val_loss',mode='min' ,patience=5, min_delta=0.0001,verbose=1)\n",
        "mcp = ModelCheckpoint(\"text_5class.h5\",monitor='val_loss',verbose=1)\n",
        "text_5class.fit(text_train,train_5class,batch_size=128,epochs=20,validation_split=0.1,callbacks=[es, mcp])\n",
        "print(\"Evaluating the model=====================================================\")\n",
        "print(text_5class.evaluate(text_test,test_5class))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 13761 samples, validate on 1529 samples\n",
            "Epoch 1/20\n",
            "13761/13761 [==============================] - 40s 3ms/step - loss: 1.4714 - acc: 0.3929 - mean_absolute_error: 0.2966 - val_loss: 1.3788 - val_acc: 0.4434 - val_mean_absolute_error: 0.2860\n",
            "\n",
            "Epoch 00001: saving model to text_5class.h5\n",
            "Epoch 2/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.4457 - acc: 0.4152 - mean_absolute_error: 0.2912 - val_loss: 1.3787 - val_acc: 0.4408 - val_mean_absolute_error: 0.2862\n",
            "\n",
            "Epoch 00002: saving model to text_5class.h5\n",
            "Epoch 3/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.4427 - acc: 0.4160 - mean_absolute_error: 0.2908 - val_loss: 1.3896 - val_acc: 0.4434 - val_mean_absolute_error: 0.2901\n",
            "\n",
            "Epoch 00003: saving model to text_5class.h5\n",
            "Epoch 4/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.4429 - acc: 0.4144 - mean_absolute_error: 0.2907 - val_loss: 1.3889 - val_acc: 0.4474 - val_mean_absolute_error: 0.2895\n",
            "\n",
            "Epoch 00004: saving model to text_5class.h5\n",
            "Epoch 5/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.4435 - acc: 0.4143 - mean_absolute_error: 0.2910 - val_loss: 1.3796 - val_acc: 0.4487 - val_mean_absolute_error: 0.2850\n",
            "\n",
            "Epoch 00005: saving model to text_5class.h5\n",
            "Epoch 6/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.4429 - acc: 0.4163 - mean_absolute_error: 0.2906 - val_loss: 1.3833 - val_acc: 0.4493 - val_mean_absolute_error: 0.2871\n",
            "\n",
            "Epoch 00006: saving model to text_5class.h5\n",
            "Epoch 7/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.4429 - acc: 0.4158 - mean_absolute_error: 0.2912 - val_loss: 1.3832 - val_acc: 0.4487 - val_mean_absolute_error: 0.2872\n",
            "\n",
            "Epoch 00007: saving model to text_5class.h5\n",
            "Epoch 00007: early stopping\n",
            "Evaluating the model=====================================================\n",
            "4832/4832 [==============================] - 13s 3ms/step\n",
            "[1.4439889745207022, 0.4149420529801324, 0.292345229166233]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN3QMtfzTCRU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "outputId": "152a2731-1b95-43ff-c230-a254463845d5"
      },
      "source": [
        "text_7class.compile('adam','categorical_crossentropy',['accuracy','mae'])\n",
        "es = EarlyStopping(monitor='val_loss',mode='min' ,patience=5, min_delta=0.0001,verbose=1)\n",
        "mcp = ModelCheckpoint(\"text_7class.h5\",monitor='val_loss',verbose=1)\n",
        "text_7class.fit(text_train,train_7class,batch_size=128,epochs=20,validation_split=0.1,callbacks=[es, mcp])\n",
        "print(\"Evaluating the model=====================================================\")\n",
        "print(text_7class.evaluate(text_test,test_7class))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 13761 samples, validate on 1529 samples\n",
            "Epoch 1/20\n",
            "13761/13761 [==============================] - 40s 3ms/step - loss: 1.5933 - acc: 0.3857 - mean_absolute_error: 0.2147 - val_loss: 1.4500 - val_acc: 0.4467 - val_mean_absolute_error: 0.2079\n",
            "\n",
            "Epoch 00001: saving model to text_7class.h5\n",
            "Epoch 2/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.5420 - acc: 0.4147 - mean_absolute_error: 0.2099 - val_loss: 1.4502 - val_acc: 0.4539 - val_mean_absolute_error: 0.2090\n",
            "\n",
            "Epoch 00002: saving model to text_7class.h5\n",
            "Epoch 3/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.5385 - acc: 0.4141 - mean_absolute_error: 0.2097 - val_loss: 1.4355 - val_acc: 0.4480 - val_mean_absolute_error: 0.2053\n",
            "\n",
            "Epoch 00003: saving model to text_7class.h5\n",
            "Epoch 4/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.5375 - acc: 0.4148 - mean_absolute_error: 0.2095 - val_loss: 1.4411 - val_acc: 0.4532 - val_mean_absolute_error: 0.2077\n",
            "\n",
            "Epoch 00004: saving model to text_7class.h5\n",
            "Epoch 5/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.5362 - acc: 0.4153 - mean_absolute_error: 0.2095 - val_loss: 1.4490 - val_acc: 0.4480 - val_mean_absolute_error: 0.2084\n",
            "\n",
            "Epoch 00005: saving model to text_7class.h5\n",
            "Epoch 6/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.5373 - acc: 0.4159 - mean_absolute_error: 0.2096 - val_loss: 1.4378 - val_acc: 0.4480 - val_mean_absolute_error: 0.2064\n",
            "\n",
            "Epoch 00006: saving model to text_7class.h5\n",
            "Epoch 7/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.5352 - acc: 0.4165 - mean_absolute_error: 0.2093 - val_loss: 1.4456 - val_acc: 0.4532 - val_mean_absolute_error: 0.2085\n",
            "\n",
            "Epoch 00007: saving model to text_7class.h5\n",
            "Epoch 8/20\n",
            "13761/13761 [==============================] - 26s 2ms/step - loss: 1.5344 - acc: 0.4153 - mean_absolute_error: 0.2093 - val_loss: 1.4522 - val_acc: 0.4532 - val_mean_absolute_error: 0.2088\n",
            "\n",
            "Epoch 00008: saving model to text_7class.h5\n",
            "Epoch 00008: early stopping\n",
            "Evaluating the model=====================================================\n",
            "4832/4832 [==============================] - 13s 3ms/step\n",
            "[1.530385459495696, 0.4145281456953642, 0.21262876837458833]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaTZB_RMTHgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(\"text_2class.h5\")\n",
        "files.download(\"text_5class.h5\")\n",
        "files.download(\"text_7class.h5\")\n",
        "\n",
        "files.download(\"audio_2class.h5\")\n",
        "files.download(\"audio_5class.h5\")\n",
        "files.download(\"audio_7class.h5\")\n",
        "\n",
        "files.download(\"video_2class.h5\")\n",
        "files.download(\"video_5class.h5\")\n",
        "files.download(\"video_7class.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGM6PcFDaspj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}