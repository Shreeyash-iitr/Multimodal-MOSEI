{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2stage_SOF.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0NKh9WQVRdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone \"https://github.com/convman/Multimodal-MOSEI.git\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxQIaMrFVdS4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "99ecb3be-c085-41bb-9583-58613cab778a"
      },
      "source": [
        "cd Multimodal-MOSEI/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Multimodal-MOSEI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rmhc_VDUVgHX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "016e9f32-97d7-4c7f-e5c1-5e0fb944ab43"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import h5py\n",
        "\n",
        "Test_labels_sad = pd.read_csv(\"mosi2uni_Test_labels_sad.csv\",header=None)\n",
        "Train_labels_sad = pd.read_csv(\"mosi2uni_Train_labels_sad.csv\",header=None)\n",
        "\n",
        "video_train = h5py.File(\"video_train.h5\",\"r\")\n",
        "print(list(video_train.keys()))\n",
        "video_train = np.array(video_train.get('d1'))\n",
        "\n",
        "video_test = h5py.File(\"video_test.h5\",\"r\")\n",
        "print(list(video_test.keys()))\n",
        "video_test = np.array(video_test.get('d1'))\n",
        "\n",
        "audio_train = h5py.File(\"audio_train.h5\",\"r\")\n",
        "print(list(audio_train.keys()))\n",
        "audio_train = np.array(audio_train.get('d1'))\n",
        "\n",
        "audio_test = h5py.File(\"audio_test.h5\",\"r\")\n",
        "print(list(audio_test.keys()))\n",
        "audio_test = np.array(audio_test.get('d1'))\n",
        "\n",
        "text_train_emb = h5py.File(\"text_train_emb.h5\",\"r\")\n",
        "print(list(text_train_emb.keys()))\n",
        "text_train_emb = np.array(text_train_emb.get('d1'))\n",
        "\n",
        "text_test_emb = h5py.File(\"text_test_emb.h5\",\"r\")\n",
        "print(list(text_test_emb.keys()))\n",
        "text_test_emb = np.array(text_test_emb.get('d1'))\n",
        "text_test_emb.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['d1']\n",
            "['d1']\n",
            "['d1']\n",
            "['d1']\n",
            "['d1']\n",
            "['d1']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4832, 20, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoPTWxp2Vlwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from time import time\n",
        "from keras import layers\n",
        "from google.colab import files\t\n",
        "from keras.models import load_model\n",
        "from scipy.io import savemat\n",
        "from keras.models import Model,Sequential,Model\n",
        "from keras.layers import *\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras import callbacks\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofSJgePHVvKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_audio_happy = load_model(\"unimodal baselines/weights/audio/weights_rnn_happy.h5\")\n",
        "model_audio_angry = load_model(\"unimodal baselines/weights/audio/weights_rnn_angry.h5\")\n",
        "\n",
        "\n",
        "model_video_happy = load_model(\"unimodal baselines/weights/video/weights_rnn_happy.h5\")\n",
        "model_video_angry = load_model(\"unimodal baselines/weights/video/weights_rnn_angry.h5\")\n",
        "\n",
        "\n",
        "model_text_happy = load_model(\"unimodal baselines/weights/text/weights_rnn_happy.h5\")\n",
        "model_text_angry = load_model(\"unimodal baselines/weights/text/weights_rnn_angry.h5\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYljyL6WV7aw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sad_video = Sequential()\n",
        "sad_audio = Sequential()\n",
        "sad_text = Sequential()\n",
        "\n",
        "for layer in model_video_sad.layers[:-1]:   #(typical late fusion)\n",
        "    sad_video.add(layer)\n",
        "for layer in sad_video.layers:\n",
        "    layer.trainable = False\n",
        "for layer in model_audio_sad.layers[:-1]:   #(typical late fusion)\n",
        "    sad_audio.add(layer)\n",
        "for layer in sad_audio.layers:\n",
        "    layer.trainable = False\n",
        "for layer in model_text_sad.layers[:-1]:   #(typical late fusion)\n",
        "    sad_text.add(layer)\n",
        "for layer in sad_text.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "Dtrain_sad_video = sad_video.predict(video_train)\n",
        "Dtest_sad_video = sad_video.predict(video_test)\n",
        "\n",
        "Dtrain_sad_audio = sad_audio.predict(audio_train)\n",
        "Dtest_sad_audio = sad_audio.predict(audio_test)\n",
        "\n",
        "Dtrain_sad_text = sad_text.predict(text_train_emb)\n",
        "Dtest_sad_text = sad_text.predict(text_test_emb)\n",
        "\n",
        "savemat(\"Ltrain_sad_video.mat\",{'val':Dtrain_sad_video})\n",
        "savemat(\"Ltest_sad_video.mat\",{'val':Dtest_sad_video})\n",
        "\n",
        "savemat(\"Ltrain_sad_audio.mat\",{'val':Dtrain_sad_audio})\n",
        "savemat(\"Ltest_sad_audio.mat\",{'val':Dtest_sad_audio})\n",
        "\n",
        "savemat(\"Ltrain_sad_text.mat\",{'val':Dtrain_sad_text})\n",
        "savemat(\"Ltest_sad_text.mat\",{'val':Dtest_sad_text})\n",
        "\n",
        "print(Dtrain_sad_text.shape,Dtest_sad_text.shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZEi8CWHatKz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7e85ed04-6e74-40e6-ca5b-13a7698207af"
      },
      "source": [
        "happy_video = Sequential()\n",
        "happy_audio = Sequential()\n",
        "happy_text = Sequential()\n",
        "\n",
        "for layer in model_video_happy.layers[:-1]:   #(typical late fusion)\n",
        "    happy_video.add(layer)\n",
        "for layer in happy_video.layers:\n",
        "    layer.trainable = False\n",
        "for layer in model_audio_happy.layers[:-1]:   #(typical late fusion)\n",
        "    happy_audio.add(layer)\n",
        "for layer in happy_audio.layers:\n",
        "    layer.trainable = False\n",
        "for layer in model_text_happy.layers[:-1]:   #(typical late fusion)\n",
        "    happy_text.add(layer)\n",
        "for layer in happy_text.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "Dtrain_happy_video = happy_video.predict(video_train)\n",
        "Dtest_happy_video = happy_video.predict(video_test)\n",
        "\n",
        "Dtrain_happy_audio = happy_audio.predict(audio_train)\n",
        "Dtest_happy_audio = happy_audio.predict(audio_test)\n",
        "\n",
        "Dtrain_happy_text = happy_text.predict(text_train_emb)\n",
        "Dtest_happy_text = happy_text.predict(text_test_emb)\n",
        "\n",
        "\n",
        "\n",
        "print(Dtrain_happy_text.shape,Dtest_happy_text.shape)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15290, 32) (4832, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lI-NchmimoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "savemat(\"Dtrain_happy_video.mat\",{'val':Dtrain_happy_video})\n",
        "savemat(\"Dtest_happy_video.mat\",{'val':Dtest_happy_video})\n",
        "\n",
        "savemat(\"Dtrain_happy_audio.mat\",{'val':Dtrain_happy_audio})\n",
        "savemat(\"Dtest_happy_audio.mat\",{'val':Dtest_happy_audio})\n",
        "\n",
        "savemat(\"Dtrain_happy_text.mat\",{'val':Dtrain_happy_text})\n",
        "savemat(\"Dtest_happy_text.mat\",{'val':Dtest_happy_text})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h83HxIpzaynw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fear_video = Sequential()\n",
        "fear_audio = Sequential()\n",
        "fear_text = Sequential()\n",
        "\n",
        "for layer in model_video_fear.layers[:-1]:   #(typical late fusion)\n",
        "    fear_video.add(layer)\n",
        "for layer in fear_video.layers:\n",
        "    layer.trainable = False\n",
        "for layer in model_audio_fear.layers[:-1]:   #(typical late fusion)\n",
        "    fear_audio.add(layer)\n",
        "for layer in fear_audio.layers:\n",
        "    layer.trainable = False\n",
        "for layer in model_text_fear.layers[:-1]:   #(typical late fusion)\n",
        "    fear_text.add(layer)\n",
        "for layer in fear_text.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "Dtrain_fear_video = fear_video.predict(video_train)\n",
        "Dtest_fear_video = fear_video.predict(video_test)\n",
        "\n",
        "Dtrain_fear_audio = fear_audio.predict(audio_train)\n",
        "Dtest_fear_audio = fear_audio.predict(audio_test)\n",
        "\n",
        "Dtrain_fear_text = fear_text.predict(text_train_emb)\n",
        "Dtest_fear_text = fear_text.predict(text_test_emb)\n",
        "\n",
        "savemat(\"Ltrain_fear_video.mat\",{'val':Dtrain_fear_video})\n",
        "savemat(\"Ltest_fear_video.mat\",{'val':Dtest_fear_video})\n",
        "\n",
        "savemat(\"Ltrain_fear_audio.mat\",{'val':Dtrain_fear_audio})\n",
        "savemat(\"Ltest_fear_audio.mat\",{'val':Dtest_fear_audio})\n",
        "\n",
        "savemat(\"Ltrain_fear_text.mat\",{'val':Dtrain_fear_text})\n",
        "savemat(\"Ltest_fear_text.mat\",{'val':Dtest_fear_text})\n",
        "\n",
        "print(Dtrain_fear_text.shape,Dtest_fear_text.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frorLq5sa0pb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "989be521-6aaf-48f4-a369-9305d07b5e56"
      },
      "source": [
        "angry_video = Sequential()\n",
        "angry_audio = Sequential()\n",
        "angry_text = Sequential()\n",
        "\n",
        "for layer in model_video_angry.layers[:-1]:   #(typical late fusion)\n",
        "    angry_video.add(layer)\n",
        "for layer in angry_video.layers:\n",
        "    layer.trainable = False\n",
        "for layer in model_audio_angry.layers[:-1]:   #(typical late fusion)\n",
        "    angry_audio.add(layer)\n",
        "for layer in angry_audio.layers:\n",
        "    layer.trainable = False\n",
        "for layer in model_text_angry.layers[:-1]:   #(typical late fusion)\n",
        "    angry_text.add(layer)\n",
        "for layer in angry_text.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "Dtrain_angry_video = angry_video.predict(video_train)\n",
        "Dtest_angry_video = angry_video.predict(video_test)\n",
        "\n",
        "Dtrain_angry_audio = angry_audio.predict(audio_train)\n",
        "Dtest_angry_audio = angry_audio.predict(audio_test)\n",
        "\n",
        "Dtrain_angry_text = angry_text.predict(text_train_emb)\n",
        "Dtest_angry_text = angry_text.predict(text_test_emb)\n",
        "\n",
        "\n",
        "\n",
        "print(Dtrain_angry_text.shape,Dtest_angry_text.shape)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15290, 32) (4832, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAnDcxtkiiBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "savemat(\"Dtrain_angry_video.mat\",{'val':Dtrain_angry_video})\n",
        "savemat(\"Dtest_angry_video.mat\",{'val':Dtest_angry_video})\n",
        "\n",
        "savemat(\"Dtrain_angry_audio.mat\",{'val':Dtrain_angry_audio})\n",
        "savemat(\"Dtest_angry_audio.mat\",{'val':Dtest_angry_audio})\n",
        "\n",
        "savemat(\"Dtrain_angry_text.mat\",{'val':Dtrain_angry_text})\n",
        "savemat(\"Dtest_angry_text.mat\",{'val':Dtest_angry_text})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0Jd18g6a-8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "disgust_video = Sequential()\n",
        "disgust_audio = Sequential()\n",
        "disgust_text = Sequential()\n",
        "\n",
        "for layer in model_video_disgust.layers[:-1]:   #(typical late fusion)\n",
        "    disgust_video.add(layer)\n",
        "for layer in disgust_video.layers:\n",
        "    layer.trainable = False\n",
        "for layer in model_audio_disgust.layers[:-1]:   #(typical late fusion)\n",
        "    disgust_audio.add(layer)\n",
        "for layer in disgust_audio.layers:\n",
        "    layer.trainable = False\n",
        "for layer in model_text_disgust.layers[:-1]:   #(typical late fusion)\n",
        "    disgust_text.add(layer)\n",
        "for layer in disgust_text.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "Dtrain_disgust_video = disgust_video.predict(video_train)\n",
        "Dtest_disgust_video = disgust_video.predict(video_test)\n",
        "\n",
        "Dtrain_disgust_audio = disgust_audio.predict(audio_train)\n",
        "Dtest_disgust_audio = disgust_audio.predict(audio_test)\n",
        "\n",
        "Dtrain_disgust_text = disgust_text.predict(text_train_emb)\n",
        "Dtest_disgust_text = disgust_text.predict(text_test_emb)\n",
        "\n",
        "savemat(\"Ltrain_disgust_video.mat\",{'val':Dtrain_disgust_video})\n",
        "savemat(\"Ltest_disgust_video.mat\",{'val':Dtest_disgust_video})\n",
        "\n",
        "savemat(\"Ltrain_disgust_audio.mat\",{'val':Dtrain_disgust_audio})\n",
        "savemat(\"Ltest_disgust_audio.mat\",{'val':Dtest_disgust_audio})\n",
        "\n",
        "savemat(\"Ltrain_disgust_text.mat\",{'val':Dtrain_disgust_text})\n",
        "savemat(\"Ltest_disgust_text.mat\",{'val':Dtest_disgust_text})\n",
        "\n",
        "print(Dtrain_disgust_text.shape,Dtest_disgust_text.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc48gtdra_9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "surprise_video = Sequential()\n",
        "surprise_audio = Sequential()\n",
        "surprise_text = Sequential()\n",
        "\n",
        "for layer in model_video_surprise.layers[:-1]:   #(typical late fusion)\n",
        "    surprise_video.add(layer)\n",
        "for layer in surprise_video.layers:\n",
        "    layer.trainable = False\n",
        "for layer in model_audio_surprise.layers[:-1]:   #(typical late fusion)\n",
        "    surprise_audio.add(layer)\n",
        "for layer in surprise_audio.layers:\n",
        "    layer.trainable = False\n",
        "for layer in model_text_surprise.layers[:-1]:   #(typical late fusion)\n",
        "    surprise_text.add(layer)\n",
        "for layer in surprise_text.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "Dtrain_surprise_video = surprise_video.predict(video_train)\n",
        "Dtest_surprise_video = surprise_video.predict(video_test)\n",
        "\n",
        "Dtrain_surprise_audio = surprise_audio.predict(audio_train)\n",
        "Dtest_surprise_audio = surprise_audio.predict(audio_test)\n",
        "\n",
        "Dtrain_surprise_text = surprise_text.predict(text_train_emb)\n",
        "Dtest_surprise_text = surprise_text.predict(text_test_emb)\n",
        "\n",
        "savemat(\"Ltrain_surprise_video.mat\",{'val':Dtrain_surprise_video})\n",
        "savemat(\"Ltest_surprise_video.mat\",{'val':Dtest_surprise_video})\n",
        "\n",
        "savemat(\"Ltrain_surprise_audio.mat\",{'val':Dtrain_surprise_audio})\n",
        "savemat(\"Ltest_surprise_audio.mat\",{'val':Dtest_surprise_audio})\n",
        "\n",
        "savemat(\"Ltrain_surprise_text.mat\",{'val':Dtrain_surprise_text})\n",
        "savemat(\"Ltest_surprise_text.mat\",{'val':Dtest_surprise_text})\n",
        "\n",
        "print(Dtrain_surprise_text.shape,Dtest_surprise_text.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji-evStgXGkZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(\"Dtest_happy_video.mat\")\n",
        "files.download(\"Dtrain_happy_video.mat\")\n",
        "\n",
        "files.download(\"Dtest_angry_video.mat\")\n",
        "files.download(\"Dtrain_angry_video.mat\")\n",
        "\n",
        "\n",
        "#################################################\n",
        "\n",
        "files.download(\"Dtest_happy_audio.mat\")\n",
        "files.download(\"Dtrain_happy_audio.mat\")\n",
        "\n",
        "files.download(\"Dtest_angry_audio.mat\")\n",
        "files.download(\"Dtrain_angry_audio.mat\")\n",
        "\n",
        "\n",
        "\n",
        "###################################################\n",
        "\n",
        "files.download(\"Dtest_happy_text.mat\")\n",
        "files.download(\"Dtrain_happy_text.mat\")\n",
        "\n",
        "files.download(\"Dtest_angry_text.mat\")\n",
        "files.download(\"Dtrain_angry_text.mat\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXWJRIK0eWq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}