{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CE mosei video.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvvXrVmENv5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget \"http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/data/audio_test.h5\"\n",
        "!wget \"http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/data/audio_train.h5\"\n",
        "!wget \"http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/data/text_test_emb.h5\"\n",
        "!wget \"http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/data/text_train_emb.h5\"\n",
        "!wget \"http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/data/video_test.h5\"\n",
        "!wget \"http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/data/video_train.h5\"\n",
        "\n",
        "!wget \"http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/labels/mosi2uni_Test_labels_2class.csv\"\n",
        "!wget \"http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/labels/mosi2uni_Test_labels_5class.csv\"\n",
        "!wget \"http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/labels/mosi2uni_Test_labels_7class.csv\"\n",
        "!wget \"http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/labels/mosi2uni_Test_labels_angry.csv\"\n",
        "!wget \"http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/labels/mosi2uni_Test_labels_disgust.csv\"\n",
        "!wget \"http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/labels/mosi2uni_Test_labels_fear.csv\"\n",
        "!wget \"http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/labels/mosi2uni_Test_labels_happy.csv\"\n",
        "!wget \"http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/labels/mosi2uni_Test_labels_sad.csv\"\n",
        "!wget \"http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/labels/mosi2uni_Test_labels_surprise.csv\"\n",
        "\n",
        "!wget \"http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/labels/mosi2uni_Train_labels_2class.csv\"\n",
        "!wget \"http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/labels/mosi2uni_Train_labels_5class.csv\"\n",
        "!wget \"http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/labels/mosi2uni_Train_labels_7class.csv\"\n",
        "!wget \"http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/labels/mosi2uni_Train_labels_angry.csv\"\n",
        "!wget \"http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/labels/mosi2uni_Train_labels_disgust.csv\"\n",
        "!wget \"http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/labels/mosi2uni_Train_labels_fear.csv\"\n",
        "!wget \"http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/labels/mosi2uni_Train_labels_happy.csv\"\n",
        "!wget \"http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/labels/mosi2uni_Train_labels_sad.csv\"\n",
        "!wget \"http://immortal.multicomp.cs.cmu.edu/raw_datasets/old_processed_data/cmu-mosei/labels/mosi2uni_Train_labels_surprise.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkM92lvwOOpC",
        "colab_type": "code",
        "outputId": "5b860f8e-9f7d-4512-ad12-e830db28bf4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import h5py\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import *\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from time import time\n",
        "import scipy\n",
        "from keras import layers\n",
        "from google.colab import files\t\n",
        "from sklearn.utils import class_weight\n",
        "from keras.models import load_model\n",
        "from keras.models import Model,Sequential,Model\n",
        "from keras.layers import *\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras import callbacks\n",
        "from keras.callbacks import *\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw9xy6zxOd14",
        "colab_type": "code",
        "outputId": "b65950b0-4ee4-4072-e079-2f77e2a25096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import h5py\n",
        "\n",
        "Test_labels_fear = np.array(pd.read_csv(\"mosi2uni_Test_labels_fear.csv\",header=None))\n",
        "Train_labels_fear = np.array(pd.read_csv(\"mosi2uni_Train_labels_fear.csv\",header=None))\n",
        "\n",
        "Test_labels_happy = np.array(pd.read_csv(\"mosi2uni_Test_labels_happy.csv\",header=None))\n",
        "Train_labels_happy = np.array(pd.read_csv(\"mosi2uni_Train_labels_happy.csv\",header=None))\n",
        "\n",
        "Test_labels_sad = np.array(pd.read_csv(\"mosi2uni_Test_labels_sad.csv\",header=None))\n",
        "Train_labels_sad = np.array(pd.read_csv(\"mosi2uni_Train_labels_sad.csv\",header=None))\n",
        "\n",
        "Test_labels_disgust = np.array(pd.read_csv(\"mosi2uni_Test_labels_disgust.csv\",header=None))\n",
        "Train_labels_disgust = np.array(pd.read_csv(\"mosi2uni_Train_labels_disgust.csv\",header=None))\n",
        "\n",
        "Test_labels_surprise = np.array(pd.read_csv(\"mosi2uni_Test_labels_surprise.csv\",header=None))\n",
        "Train_labels_surprise = np.array(pd.read_csv(\"mosi2uni_Train_labels_surprise.csv\",header=None))\n",
        "\n",
        "Test_labels_angry = np.array(pd.read_csv(\"mosi2uni_Test_labels_angry.csv\",header=None))\n",
        "Train_labels_angry = np.array(pd.read_csv(\"mosi2uni_Train_labels_angry.csv\",header=None))\n",
        "\n",
        "X_train = h5py.File(\"video_train.h5\",\"r\")\n",
        "X_train = np.array(X_train.get('d1'))\n",
        "\n",
        "X_test = h5py.File(\"video_test.h5\",\"r\")\n",
        "X_test = np.array(X_test.get('d1'))\n",
        "print(X_train.shape,X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15290, 20, 35) (4832, 20, 35)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK244Hv6OleC",
        "colab_type": "code",
        "outputId": "5dc4f032-fd30-4006-ad8b-268447f22883",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "class_weight = class_weight.compute_class_weight('balanced',np.unique(Train_labels_happy.squeeze()),Train_labels_happy.squeeze())\n",
        "print(class_weight)\n",
        "\n",
        "i = Input(shape=(20,35))\n",
        "x = LSTM(64,return_sequences = True)(i)\n",
        "x = LSTM(32,return_sequences = True)(x)\n",
        "x = LSTM(32,return_sequences = False)(x)\n",
        "x = Dense(32,activation='relu')(x)\n",
        "x = Dense(1,activation='sigmoid')(x)\n",
        "\n",
        "model = Model(i,x)\n",
        "print(model.summary())\n",
        "model.compile('adam','binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "es = EarlyStopping(monitor='val_acc',mode='max' ,patience=5, min_delta=0.0001,verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2,patience=2,min_lr=0.00001)\n",
        "model.fit(X_train,Train_labels_happy,512,epochs=100,validation_split=0.1,callbacks=[es,reduce_lr],\n",
        "         class_weight=dict(enumerate(class_weight)))\n",
        "\n",
        "\n",
        "y_pred = (model.predict(X_test)>0.5).astype(\"float\")\n",
        "y_true = Test_labels_happy\n",
        "cm = confusion_matrix(y_true,y_pred)\n",
        "\n",
        "p = precision_score(y_true,y_pred)\n",
        "a = accuracy_score(y_true,y_pred)\n",
        "r = recall_score(y_true,y_pred)\n",
        "f = f1_score(y_true,y_pred)\n",
        "print(cm)\n",
        "print(\"accuracy  :\",a)\n",
        "print(\"f1 score  :\",f)\n",
        "print(\"precision :\",p)\n",
        "print(\"recall    :\",r)\n",
        "\n",
        "\n",
        "TP = cm[1][1]\n",
        "TN = cm[0][0]\n",
        "P = Test_labels_happy.sum()\n",
        "N = 4832-P\n",
        "wa = ((TP*N/P) + TN)/(0.02*N)\n",
        "print(\"WA        :\",wa)\n",
        "print(classification_report(y_true,y_pred))\n",
        "model.save(\"video_happy.h5\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.07027859 0.93838223]\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_27 (InputLayer)        (None, 20, 35)            0         \n",
            "_________________________________________________________________\n",
            "lstm_73 (LSTM)               (None, 20, 64)            25600     \n",
            "_________________________________________________________________\n",
            "lstm_74 (LSTM)               (None, 20, 32)            12416     \n",
            "_________________________________________________________________\n",
            "lstm_75 (LSTM)               (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_55 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 47,425\n",
            "Trainable params: 47,425\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13761 samples, validate on 1529 samples\n",
            "Epoch 1/100\n",
            "13761/13761 [==============================] - 17s 1ms/step - loss: 0.6693 - acc: 0.6013 - val_loss: 0.6690 - val_acc: 0.5952\n",
            "Epoch 2/100\n",
            "13761/13761 [==============================] - 4s 316us/step - loss: 0.6281 - acc: 0.6422 - val_loss: 0.6569 - val_acc: 0.6089\n",
            "Epoch 3/100\n",
            "13761/13761 [==============================] - 4s 316us/step - loss: 0.6103 - acc: 0.6595 - val_loss: 0.6639 - val_acc: 0.6030\n",
            "Epoch 4/100\n",
            "13761/13761 [==============================] - 4s 316us/step - loss: 0.5949 - acc: 0.6771 - val_loss: 0.6650 - val_acc: 0.6115\n",
            "Epoch 5/100\n",
            "13761/13761 [==============================] - 4s 314us/step - loss: 0.5822 - acc: 0.6869 - val_loss: 0.6703 - val_acc: 0.6141\n",
            "Epoch 6/100\n",
            "13761/13761 [==============================] - 4s 317us/step - loss: 0.5693 - acc: 0.6961 - val_loss: 0.6871 - val_acc: 0.6161\n",
            "Epoch 7/100\n",
            "13761/13761 [==============================] - 4s 312us/step - loss: 0.5579 - acc: 0.7034 - val_loss: 0.6851 - val_acc: 0.6102\n",
            "Epoch 8/100\n",
            "13761/13761 [==============================] - 4s 314us/step - loss: 0.5433 - acc: 0.7147 - val_loss: 0.7049 - val_acc: 0.6167\n",
            "Epoch 9/100\n",
            "13761/13761 [==============================] - 4s 314us/step - loss: 0.5323 - acc: 0.7239 - val_loss: 0.7282 - val_acc: 0.6089\n",
            "Epoch 10/100\n",
            "13761/13761 [==============================] - 4s 314us/step - loss: 0.5219 - acc: 0.7311 - val_loss: 0.7291 - val_acc: 0.6174\n",
            "Epoch 11/100\n",
            "13761/13761 [==============================] - 4s 313us/step - loss: 0.5098 - acc: 0.7381 - val_loss: 0.7397 - val_acc: 0.6154\n",
            "Epoch 12/100\n",
            "13761/13761 [==============================] - 4s 311us/step - loss: 0.4950 - acc: 0.7469 - val_loss: 0.7608 - val_acc: 0.5984\n",
            "Epoch 13/100\n",
            "13761/13761 [==============================] - 4s 317us/step - loss: 0.4700 - acc: 0.7630 - val_loss: 0.7928 - val_acc: 0.6161\n",
            "Epoch 14/100\n",
            "13761/13761 [==============================] - 4s 316us/step - loss: 0.4582 - acc: 0.7683 - val_loss: 0.8192 - val_acc: 0.6076\n",
            "Epoch 15/100\n",
            "13761/13761 [==============================] - 4s 314us/step - loss: 0.4495 - acc: 0.7746 - val_loss: 0.8232 - val_acc: 0.6082\n",
            "Epoch 00015: early stopping\n",
            "[[1797  513]\n",
            " [1250 1272]]\n",
            "accuracy  : 0.6351407284768212\n",
            "f1 score  : 0.5906663570931042\n",
            "precision : 0.7126050420168067\n",
            "recall    : 0.5043616177636796\n",
            "WA        : 64.11418478428787\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.78      0.67      2310\n",
            "           1       0.71      0.50      0.59      2522\n",
            "\n",
            "    accuracy                           0.64      4832\n",
            "   macro avg       0.65      0.64      0.63      4832\n",
            "weighted avg       0.65      0.64      0.63      4832\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxv1VmElOtjz",
        "colab_type": "code",
        "outputId": "de40fc53-961b-44a9-cc94-f6b29e84c480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        }
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "class_weight = class_weight.compute_class_weight('balanced',np.unique(Train_labels_angry.squeeze()),Train_labels_angry.squeeze())\n",
        "print(class_weight)\n",
        "\n",
        "i = Input(shape=(20,35))\n",
        "x = LSTM(32,return_sequences = True)(i)\n",
        "x = LSTM(32,return_sequences = True)(x)\n",
        "x = LSTM(32,return_sequences = True)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128,activation='relu')(x)\n",
        "x = Dense(1,activation='sigmoid')(x)\n",
        "\n",
        "model = Model(i,x)\n",
        "print(model.summary())\n",
        "model.compile('adam','binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "es = EarlyStopping(monitor='val_acc',mode='max' ,patience=5, min_delta=0.0001,verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2,patience=2,min_lr=0.00001)\n",
        "model.fit(X_train,Train_labels_angry,512,epochs=100,validation_split=0.1,callbacks=[es,reduce_lr],\n",
        "          class_weight=dict(enumerate(class_weight)))\n",
        "\n",
        "\n",
        "y_pred = (model.predict(X_test)>0.5).astype(\"float\")\n",
        "y_true = Test_labels_angry\n",
        "cm = confusion_matrix(y_true,y_pred)\n",
        "\n",
        "p = precision_score(y_true,y_pred)\n",
        "a = accuracy_score(y_true,y_pred)\n",
        "r = recall_score(y_true,y_pred)\n",
        "f = f1_score(y_true,y_pred)\n",
        "print(cm)\n",
        "print(\"accuracy  :\",a)\n",
        "print(\"f1 score  :\",f)\n",
        "print(\"precision :\",p)\n",
        "print(\"recall    :\",r)\n",
        "\n",
        "\n",
        "TP = cm[1][1]\n",
        "TN = cm[0][0]\n",
        "P = Test_labels_angry.sum()\n",
        "N = 4832-P\n",
        "wa = ((TP*N/P) + TN)/(0.02*N)\n",
        "print(\"WA        :\",wa)\n",
        "print(classification_report(y_true,y_pred))\n",
        "model.save(\"video_angry.h5\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.64531105 2.22044728]\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_28 (InputLayer)        (None, 20, 35)            0         \n",
            "_________________________________________________________________\n",
            "lstm_76 (LSTM)               (None, 20, 32)            8704      \n",
            "_________________________________________________________________\n",
            "lstm_77 (LSTM)               (None, 20, 32)            8320      \n",
            "_________________________________________________________________\n",
            "lstm_78 (LSTM)               (None, 20, 32)            8320      \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 640)               0         \n",
            "_________________________________________________________________\n",
            "dense_56 (Dense)             (None, 128)               82048     \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 107,521\n",
            "Trainable params: 107,521\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13761 samples, validate on 1529 samples\n",
            "Epoch 1/100\n",
            "13761/13761 [==============================] - 31s 2ms/step - loss: 0.6780 - acc: 0.5980 - val_loss: 0.6459 - val_acc: 0.6161\n",
            "Epoch 2/100\n",
            "13761/13761 [==============================] - 7s 477us/step - loss: 0.6497 - acc: 0.6119 - val_loss: 0.6501 - val_acc: 0.5834\n",
            "Epoch 3/100\n",
            "13761/13761 [==============================] - 7s 477us/step - loss: 0.6395 - acc: 0.6128 - val_loss: 0.6502 - val_acc: 0.5939\n",
            "Epoch 4/100\n",
            "13761/13761 [==============================] - 7s 515us/step - loss: 0.6260 - acc: 0.6327 - val_loss: 0.6488 - val_acc: 0.5939\n",
            "Epoch 5/100\n",
            "13761/13761 [==============================] - 7s 521us/step - loss: 0.6222 - acc: 0.6272 - val_loss: 0.6570 - val_acc: 0.5762\n",
            "Epoch 6/100\n",
            "13761/13761 [==============================] - 7s 538us/step - loss: 0.6187 - acc: 0.6252 - val_loss: 0.6553 - val_acc: 0.5840\n",
            "Epoch 00006: early stopping\n",
            "[[2141 1720]\n",
            " [ 300  671]]\n",
            "accuracy  : 0.581953642384106\n",
            "f1 score  : 0.39916716240333133\n",
            "precision : 0.2806357172731075\n",
            "recall    : 0.6910401647785788\n",
            "WA        : 62.27798596490668\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.55      0.68      3861\n",
            "           1       0.28      0.69      0.40       971\n",
            "\n",
            "    accuracy                           0.58      4832\n",
            "   macro avg       0.58      0.62      0.54      4832\n",
            "weighted avg       0.76      0.58      0.62      4832\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6wFTJyaQMZr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "87171059-a4e2-4400-be50-b19526e9e93b"
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "class_weight = class_weight.compute_class_weight('balanced',np.unique(Train_labels_sad.squeeze()),Train_labels_sad.squeeze())\n",
        "print(class_weight)\n",
        "\n",
        "i = Input(shape=(20,35))\n",
        "x = LSTM(32,return_sequences = True)(i)\n",
        "x = LSTM(32,return_sequences = True)(x)\n",
        "x = LSTM(32,return_sequences = True)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128,activation='relu')(x)\n",
        "x = Dense(1,activation='sigmoid')(x)\n",
        "\n",
        "model = Model(i,x)\n",
        "print(model.summary())\n",
        "model.compile('adam','binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "es = EarlyStopping(monitor='val_acc',mode='max' ,patience=5, min_delta=0.0001,verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2,patience=2,min_lr=0.00001)\n",
        "model.fit(X_train,Train_labels_sad,512,epochs=100,validation_split=0.1,callbacks=[es,reduce_lr],\n",
        "          class_weight=dict(enumerate(class_weight)))\n",
        "\n",
        "\n",
        "y_pred = (model.predict(X_test)>0.5).astype(\"float\")\n",
        "y_true = Test_labels_sad\n",
        "cm = confusion_matrix(y_true,y_pred)\n",
        "\n",
        "p = precision_score(y_true,y_pred)\n",
        "a = accuracy_score(y_true,y_pred)\n",
        "r = recall_score(y_true,y_pred)\n",
        "f = f1_score(y_true,y_pred)\n",
        "print(cm)\n",
        "print(\"accuracy  :\",a)\n",
        "print(\"f1 score  :\",f)\n",
        "print(\"precision :\",p)\n",
        "print(\"recall    :\",r)\n",
        "\n",
        "\n",
        "TP = cm[1][1]\n",
        "TN = cm[0][0]\n",
        "P = Test_labels_sad.sum()\n",
        "N = 4832-P\n",
        "wa = ((TP*N/P) + TN)/(0.02*N)\n",
        "print(\"WA        :\",wa)\n",
        "print(classification_report(y_true,y_pred))\n",
        "model.save(\"video_sad.h5\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.67155657 1.95724526]\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_29 (InputLayer)        (None, 20, 35)            0         \n",
            "_________________________________________________________________\n",
            "lstm_79 (LSTM)               (None, 20, 32)            8704      \n",
            "_________________________________________________________________\n",
            "lstm_80 (LSTM)               (None, 20, 32)            8320      \n",
            "_________________________________________________________________\n",
            "lstm_81 (LSTM)               (None, 20, 32)            8320      \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 640)               0         \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 128)               82048     \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 107,521\n",
            "Trainable params: 107,521\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13761 samples, validate on 1529 samples\n",
            "Epoch 1/100\n",
            "13761/13761 [==============================] - 31s 2ms/step - loss: 0.6863 - acc: 0.5298 - val_loss: 0.6587 - val_acc: 0.5343\n",
            "Epoch 2/100\n",
            "13761/13761 [==============================] - 7s 519us/step - loss: 0.6685 - acc: 0.5349 - val_loss: 0.6556 - val_acc: 0.5095\n",
            "Epoch 3/100\n",
            "13761/13761 [==============================] - 7s 517us/step - loss: 0.6580 - acc: 0.5473 - val_loss: 0.6541 - val_acc: 0.5389\n",
            "Epoch 4/100\n",
            "13761/13761 [==============================] - 7s 541us/step - loss: 0.6487 - acc: 0.5617 - val_loss: 0.6519 - val_acc: 0.5618\n",
            "Epoch 5/100\n",
            "13761/13761 [==============================] - 6s 471us/step - loss: 0.6398 - acc: 0.5762 - val_loss: 0.6619 - val_acc: 0.5082\n",
            "Epoch 6/100\n",
            "13761/13761 [==============================] - 7s 504us/step - loss: 0.6303 - acc: 0.5768 - val_loss: 0.6564 - val_acc: 0.5598\n",
            "Epoch 7/100\n",
            "13761/13761 [==============================] - 6s 407us/step - loss: 0.6158 - acc: 0.5942 - val_loss: 0.6663 - val_acc: 0.5415\n",
            "Epoch 8/100\n",
            "13761/13761 [==============================] - 7s 499us/step - loss: 0.6107 - acc: 0.5959 - val_loss: 0.6680 - val_acc: 0.5441\n",
            "Epoch 9/100\n",
            "13761/13761 [==============================] - 7s 516us/step - loss: 0.6067 - acc: 0.5993 - val_loss: 0.6681 - val_acc: 0.5474\n",
            "Epoch 00009: early stopping\n",
            "[[1724 1774]\n",
            " [ 407  927]]\n",
            "accuracy  : 0.5486341059602649\n",
            "f1 score  : 0.45947955390334566\n",
            "precision : 0.34320621991854866\n",
            "recall    : 0.6949025487256372\n",
            "WA        : 59.387780380821596\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.49      0.61      3498\n",
            "           1       0.34      0.69      0.46      1334\n",
            "\n",
            "    accuracy                           0.55      4832\n",
            "   macro avg       0.58      0.59      0.54      4832\n",
            "weighted avg       0.68      0.55      0.57      4832\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-W1y0gsUgoI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        },
        "outputId": "f9ad4451-1e73-4036-e9c9-43cd7f17d369"
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "class_weight = class_weight.compute_class_weight('balanced',np.unique(Train_labels_fear.squeeze()),Train_labels_fear.squeeze())\n",
        "print(class_weight)\n",
        "\n",
        "i = Input(shape=(20,35))\n",
        "x = LSTM(32,return_sequences = True)(i)\n",
        "x = LSTM(32,return_sequences = True)(x)\n",
        "x = LSTM(32,return_sequences = True)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128,activation='relu')(x)\n",
        "x = Dense(1,activation='sigmoid')(x)\n",
        "\n",
        "model = Model(i,x)\n",
        "print(model.summary())\n",
        "model.compile('adam','binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "es = EarlyStopping(monitor='val_acc',mode='max' ,patience=5, min_delta=0.0001,verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2,patience=2,min_lr=0.00001)\n",
        "model.fit(X_train,Train_labels_fear,512,epochs=100,validation_split=0.1,callbacks=[es,reduce_lr],\n",
        "          class_weight=dict(enumerate(class_weight)))\n",
        "\n",
        "\n",
        "y_pred = (model.predict(X_test)>0.5).astype(\"float\")\n",
        "y_true = Test_labels_fear\n",
        "cm = confusion_matrix(y_true,y_pred)\n",
        "\n",
        "p = precision_score(y_true,y_pred)\n",
        "a = accuracy_score(y_true,y_pred)\n",
        "r = recall_score(y_true,y_pred)\n",
        "f = f1_score(y_true,y_pred)\n",
        "print(cm)\n",
        "print(\"accuracy  :\",a)\n",
        "print(\"f1 score  :\",f)\n",
        "print(\"precision :\",p)\n",
        "print(\"recall    :\",r)\n",
        "\n",
        "\n",
        "TP = cm[1][1]\n",
        "TN = cm[0][0]\n",
        "P = Test_labels_fear.sum()\n",
        "N = 4832-P\n",
        "wa = ((TP*N/P) + TN)/(0.02*N)\n",
        "print(\"WA        :\",wa)\n",
        "print(classification_report(y_true,y_pred))\n",
        "model.save(\"video_fear.h5\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.54720492 5.79605762]\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_30 (InputLayer)        (None, 20, 35)            0         \n",
            "_________________________________________________________________\n",
            "lstm_82 (LSTM)               (None, 20, 32)            8704      \n",
            "_________________________________________________________________\n",
            "lstm_83 (LSTM)               (None, 20, 32)            8320      \n",
            "_________________________________________________________________\n",
            "lstm_84 (LSTM)               (None, 20, 32)            8320      \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 640)               0         \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 128)               82048     \n",
            "_________________________________________________________________\n",
            "dense_61 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 107,521\n",
            "Trainable params: 107,521\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13761 samples, validate on 1529 samples\n",
            "Epoch 1/100\n",
            "13761/13761 [==============================] - 31s 2ms/step - loss: 0.6680 - acc: 0.4997 - val_loss: 0.7104 - val_acc: 0.5860\n",
            "Epoch 2/100\n",
            "13761/13761 [==============================] - 8s 553us/step - loss: 0.6416 - acc: 0.5972 - val_loss: 0.7107 - val_acc: 0.5180\n",
            "Epoch 3/100\n",
            "13761/13761 [==============================] - 7s 540us/step - loss: 0.6305 - acc: 0.6018 - val_loss: 0.7023 - val_acc: 0.5278\n",
            "Epoch 4/100\n",
            "13761/13761 [==============================] - 7s 485us/step - loss: 0.6168 - acc: 0.6252 - val_loss: 0.7187 - val_acc: 0.5664\n",
            "Epoch 5/100\n",
            "13761/13761 [==============================] - 6s 424us/step - loss: 0.6116 - acc: 0.6449 - val_loss: 0.7182 - val_acc: 0.5644\n",
            "Epoch 6/100\n",
            "13761/13761 [==============================] - 6s 413us/step - loss: 0.6071 - acc: 0.6449 - val_loss: 0.7181 - val_acc: 0.5710\n",
            "Epoch 00006: early stopping\n",
            "[[2914 1586]\n",
            " [ 123  209]]\n",
            "accuracy  : 0.6463162251655629\n",
            "f1 score  : 0.19652092148566055\n",
            "precision : 0.11643454038997214\n",
            "recall    : 0.6295180722891566\n",
            "WA        : 63.85368139223561\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.65      0.77      4500\n",
            "           1       0.12      0.63      0.20       332\n",
            "\n",
            "    accuracy                           0.65      4832\n",
            "   macro avg       0.54      0.64      0.48      4832\n",
            "weighted avg       0.90      0.65      0.73      4832\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se-7tW-wUjNp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 971
        },
        "outputId": "571f2600-ca1a-4f21-f29f-15bee30565c0"
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "class_weight = class_weight.compute_class_weight('balanced',np.unique(Train_labels_disgust.squeeze()),Train_labels_disgust.squeeze())\n",
        "print(class_weight)\n",
        "\n",
        "i = Input(shape=(20,35))\n",
        "x = LSTM(32,return_sequences = True)(i)\n",
        "x = LSTM(32,return_sequences = True)(x)\n",
        "x = LSTM(32,return_sequences = True)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128,activation='relu')(x)\n",
        "x = Dense(1,activation='sigmoid')(x)\n",
        "\n",
        "model = Model(i,x)\n",
        "print(model.summary())\n",
        "model.compile('adam','binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "es = EarlyStopping(monitor='val_acc',mode='max' ,patience=5, min_delta=0.0001,verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2,patience=2,min_lr=0.00001)\n",
        "model.fit(X_train,Train_labels_disgust,512,epochs=100,validation_split=0.1,callbacks=[es,reduce_lr],\n",
        "          class_weight=dict(enumerate(class_weight)))\n",
        "\n",
        "\n",
        "y_pred = (model.predict(X_test)>0.5).astype(\"float\")\n",
        "y_true = Test_labels_disgust\n",
        "cm = confusion_matrix(y_true,y_pred)\n",
        "\n",
        "p = precision_score(y_true,y_pred)\n",
        "a = accuracy_score(y_true,y_pred)\n",
        "r = recall_score(y_true,y_pred)\n",
        "f = f1_score(y_true,y_pred)\n",
        "print(cm)\n",
        "print(\"accuracy  :\",a)\n",
        "print(\"f1 score  :\",f)\n",
        "print(\"precision :\",p)\n",
        "print(\"recall    :\",r)\n",
        "\n",
        "\n",
        "TP = cm[1][1]\n",
        "TN = cm[0][0]\n",
        "P = Test_labels_disgust.sum()\n",
        "N = 4832-P\n",
        "wa = ((TP*N/P) + TN)/(0.02*N)\n",
        "print(\"WA        :\",wa)\n",
        "print(classification_report(y_true,y_pred))\n",
        "model.save(\"video_disgust.h5\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.60819411 2.81066176]\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_31 (InputLayer)        (None, 20, 35)            0         \n",
            "_________________________________________________________________\n",
            "lstm_85 (LSTM)               (None, 20, 32)            8704      \n",
            "_________________________________________________________________\n",
            "lstm_86 (LSTM)               (None, 20, 32)            8320      \n",
            "_________________________________________________________________\n",
            "lstm_87 (LSTM)               (None, 20, 32)            8320      \n",
            "_________________________________________________________________\n",
            "flatten_13 (Flatten)         (None, 640)               0         \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 128)               82048     \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 107,521\n",
            "Trainable params: 107,521\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13761 samples, validate on 1529 samples\n",
            "Epoch 1/100\n",
            "13761/13761 [==============================] - 25s 2ms/step - loss: 0.6546 - acc: 0.6544 - val_loss: 0.5861 - val_acc: 0.7044\n",
            "Epoch 2/100\n",
            "13761/13761 [==============================] - 4s 313us/step - loss: 0.6149 - acc: 0.6986 - val_loss: 0.5808 - val_acc: 0.7286\n",
            "Epoch 3/100\n",
            "13761/13761 [==============================] - 4s 313us/step - loss: 0.6047 - acc: 0.7042 - val_loss: 0.5822 - val_acc: 0.7286\n",
            "Epoch 4/100\n",
            "13761/13761 [==============================] - 4s 313us/step - loss: 0.5988 - acc: 0.6944 - val_loss: 0.5831 - val_acc: 0.6991\n",
            "Epoch 5/100\n",
            "13761/13761 [==============================] - 4s 315us/step - loss: 0.5864 - acc: 0.7007 - val_loss: 0.5843 - val_acc: 0.7247\n",
            "Epoch 6/100\n",
            "13761/13761 [==============================] - 4s 314us/step - loss: 0.5819 - acc: 0.6994 - val_loss: 0.5854 - val_acc: 0.7122\n",
            "Epoch 7/100\n",
            "13761/13761 [==============================] - 4s 313us/step - loss: 0.5787 - acc: 0.6968 - val_loss: 0.5864 - val_acc: 0.7162\n",
            "Epoch 00007: early stopping\n",
            "[[2623 1287]\n",
            " [ 240  682]]\n",
            "accuracy  : 0.6839817880794702\n",
            "f1 score  : 0.47180906260809413\n",
            "precision : 0.3463687150837989\n",
            "recall    : 0.7396963123644251\n",
            "WA        : 70.5270151067123\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.67      0.77      3910\n",
            "           1       0.35      0.74      0.47       922\n",
            "\n",
            "    accuracy                           0.68      4832\n",
            "   macro avg       0.63      0.71      0.62      4832\n",
            "weighted avg       0.81      0.68      0.72      4832\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psDeCRgMUl19",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "37750ad4-a58b-4a73-922b-1d52813ce565"
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "class_weight = class_weight.compute_class_weight('balanced',np.unique(Train_labels_surprise.squeeze()),Train_labels_surprise.squeeze())\n",
        "print(class_weight)\n",
        "\n",
        "i = Input(shape=(20,35))\n",
        "x = LSTM(32,return_sequences = True)(i)\n",
        "x = LSTM(32,return_sequences = True)(x)\n",
        "x = LSTM(32,return_sequences = True)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128,activation='relu')(x)\n",
        "x = Dense(1,activation='sigmoid')(x)\n",
        "\n",
        "model = Model(i,x)\n",
        "print(model.summary())\n",
        "model.compile('adam','binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "es = EarlyStopping(monitor='val_acc',mode='max' ,patience=5, min_delta=0.0001,verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2,patience=2,min_lr=0.00001)\n",
        "model.fit(X_train,Train_labels_surprise,512,epochs=100,validation_split=0.1,callbacks=[es,reduce_lr],\n",
        "          class_weight=dict(enumerate(class_weight)))\n",
        "\n",
        "\n",
        "y_pred = (model.predict(X_test)>0.5).astype(\"float\")\n",
        "y_true = Test_labels_surprise\n",
        "cm = confusion_matrix(y_true,y_pred)\n",
        "\n",
        "p = precision_score(y_true,y_pred)\n",
        "a = accuracy_score(y_true,y_pred)\n",
        "r = recall_score(y_true,y_pred)\n",
        "f = f1_score(y_true,y_pred)\n",
        "print(cm)\n",
        "print(\"accuracy  :\",a)\n",
        "print(\"f1 score  :\",f)\n",
        "print(\"precision :\",p)\n",
        "print(\"recall    :\",r)\n",
        "\n",
        "\n",
        "TP = cm[1][1]\n",
        "TN = cm[0][0]\n",
        "P = Test_labels_surprise.sum()\n",
        "N = 4832-P\n",
        "wa = ((TP*N/P) + TN)/(0.02*N)\n",
        "print(\"WA        :\",wa)\n",
        "print(classification_report(y_true,y_pred))\n",
        "model.save(\"video_surprise.h5\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.55689103 4.8943662 ]\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_32 (InputLayer)        (None, 20, 35)            0         \n",
            "_________________________________________________________________\n",
            "lstm_88 (LSTM)               (None, 20, 32)            8704      \n",
            "_________________________________________________________________\n",
            "lstm_89 (LSTM)               (None, 20, 32)            8320      \n",
            "_________________________________________________________________\n",
            "lstm_90 (LSTM)               (None, 20, 32)            8320      \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 640)               0         \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 128)               82048     \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 107,521\n",
            "Trainable params: 107,521\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 13761 samples, validate on 1529 samples\n",
            "Epoch 1/100\n",
            "13761/13761 [==============================] - 20s 1ms/step - loss: 0.6950 - acc: 0.4235 - val_loss: 0.6467 - val_acc: 0.5121\n",
            "Epoch 2/100\n",
            "13761/13761 [==============================] - 4s 319us/step - loss: 0.6838 - acc: 0.4678 - val_loss: 0.6450 - val_acc: 0.4787\n",
            "Epoch 3/100\n",
            "13761/13761 [==============================] - 4s 316us/step - loss: 0.6756 - acc: 0.4626 - val_loss: 0.6442 - val_acc: 0.4990\n",
            "Epoch 4/100\n",
            "13761/13761 [==============================] - 4s 314us/step - loss: 0.6632 - acc: 0.4806 - val_loss: 0.6438 - val_acc: 0.5141\n",
            "Epoch 5/100\n",
            "13761/13761 [==============================] - 4s 312us/step - loss: 0.6564 - acc: 0.4923 - val_loss: 0.6451 - val_acc: 0.5284\n",
            "Epoch 6/100\n",
            "13761/13761 [==============================] - 4s 315us/step - loss: 0.6516 - acc: 0.4975 - val_loss: 0.6463 - val_acc: 0.5147\n",
            "Epoch 7/100\n",
            "13761/13761 [==============================] - 4s 313us/step - loss: 0.6469 - acc: 0.4952 - val_loss: 0.6485 - val_acc: 0.5422\n",
            "Epoch 8/100\n",
            "13761/13761 [==============================] - 4s 314us/step - loss: 0.6422 - acc: 0.5125 - val_loss: 0.6496 - val_acc: 0.5173\n",
            "Epoch 9/100\n",
            "13761/13761 [==============================] - 4s 313us/step - loss: 0.6369 - acc: 0.4963 - val_loss: 0.6538 - val_acc: 0.5572\n",
            "Epoch 10/100\n",
            "13761/13761 [==============================] - 4s 315us/step - loss: 0.6313 - acc: 0.5150 - val_loss: 0.6549 - val_acc: 0.5101\n",
            "Epoch 11/100\n",
            "13761/13761 [==============================] - 4s 314us/step - loss: 0.6260 - acc: 0.5093 - val_loss: 0.6549 - val_acc: 0.5226\n",
            "Epoch 12/100\n",
            "13761/13761 [==============================] - 4s 314us/step - loss: 0.6184 - acc: 0.5106 - val_loss: 0.6563 - val_acc: 0.5284\n",
            "Epoch 13/100\n",
            "13761/13761 [==============================] - 4s 315us/step - loss: 0.6170 - acc: 0.5173 - val_loss: 0.6581 - val_acc: 0.5284\n",
            "Epoch 14/100\n",
            "13761/13761 [==============================] - 4s 315us/step - loss: 0.6156 - acc: 0.5167 - val_loss: 0.6583 - val_acc: 0.5298\n",
            "Epoch 00014: early stopping\n",
            "[[2025 2328]\n",
            " [ 193  286]]\n",
            "accuracy  : 0.4782698675496689\n",
            "f1 score  : 0.18493372130617522\n",
            "precision : 0.10941086457536343\n",
            "recall    : 0.5970772442588727\n",
            "WA        : 53.11368302617589\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.47      0.62      4353\n",
            "           1       0.11      0.60      0.18       479\n",
            "\n",
            "    accuracy                           0.48      4832\n",
            "   macro avg       0.51      0.53      0.40      4832\n",
            "weighted avg       0.83      0.48      0.57      4832\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXjICcdMUpJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(\"video_happy.h5\")\n",
        "files.download(\"video_angry.h5\")\n",
        "files.download(\"video_sad.h5\")\n",
        "files.download(\"video_fear.h5\")\n",
        "files.download(\"video_surprise.h5\")\n",
        "files.download(\"video_disgust.h5\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzhZ9BCziNub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}